{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **[Data4Life] - Introduction to Data Science**\n",
    "Topic ***NBA*** - Group ***16***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Team Members**\n",
    "\n",
    "<center>\n",
    "\n",
    "| No. | Name                   | Student ID |\n",
    "|-----|------------------------|------------|\n",
    "| 1   | Trần Nguyễn Nhật Cường | 22127048   |\n",
    "| 2   | Huỳnh Tấn Đạt          | 22127059   |\n",
    "| 3   | Nguyễn Công Tuấn       | 22127436   |  \n",
    "| 4   | Trần Đăng Tuấn         | 22127438   |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Overview**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will identify two specific URLs which are:\n",
    "- [Offcial NBA Stat](https://www.nba.com/stats)\n",
    "- [Basketball Reference](https://www.basketball-reference.com/)\n",
    "\n",
    "Our team will use for data crawling to support our analysis. The targeted data types include:\n",
    "- Team Statistics (Total): Comprehensive data summarizing team performance metrics.\n",
    "- Player Statistics (Total): Aggregate performance data for individual players across relevant metrics.\n",
    "- Player Information: Detailed player profiles, including demographic, biographical, and career-specific information.\n",
    "- Rookie Player Statistics: Performance metrics specific to rookie players in the league.\n",
    "\n",
    "These URLs will serve as primary data sources, enabling us to compile and analyze the necessary information effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.edge.service import Service\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Collection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Offcial NBA Stat**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Player's profile**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "# Function to scrape the team roster data\n",
    "def scrape_roster(url, season):\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(2)  # Wait for the page to load completely\n",
    "\n",
    "    # Wait for the team name section to load\n",
    "    try:\n",
    "        team_name_section = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"TeamHeader_name__MmHlP\"))\n",
    "        )\n",
    "    except:\n",
    "        print(f\"Unable to load the team name for {url}\")\n",
    "        return []\n",
    "\n",
    "    # Extract team name\n",
    "    team_name_parts = team_name_section.find_elements(By.TAG_NAME, \"div\")\n",
    "    team_name = \" \".join(\n",
    "        [part.text.strip() for part in team_name_parts if part.text.strip()]\n",
    "    )\n",
    "\n",
    "    # Wait for the Roster section to load completely\n",
    "    try:\n",
    "        rows_section = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"Crom_body__UYOcU\"))\n",
    "        )\n",
    "    except:\n",
    "        print(f\"Unable to load the roster section for {team_name}\")\n",
    "        return []\n",
    "\n",
    "    # Extract header for the CSV file\n",
    "    header = [\n",
    "        \"Player\",\n",
    "        \"No.\",\n",
    "        \"Pos\",\n",
    "        \"Height\",\n",
    "        \"Weight\",\n",
    "        \"Birthdate\",\n",
    "        \"Age\",\n",
    "        \"Exp\",\n",
    "        \"School\",\n",
    "        \"How Acquired\",\n",
    "        \"Team Name\",\n",
    "        \"Player Link\",\n",
    "        \"Season\",\n",
    "    ]\n",
    "\n",
    "    # Store the roster data\n",
    "    data = []\n",
    "\n",
    "    # Find all rows in the roster table\n",
    "    rows = rows_section.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "    for row in rows:\n",
    "        columns = row.find_elements(By.TAG_NAME, \"td\")\n",
    "\n",
    "        # Ensure row has data columns\n",
    "        if len(columns) > 0:\n",
    "            player_name = columns[0].text.strip()\n",
    "            player_link_elements = columns[0].find_elements(By.TAG_NAME, \"a\")\n",
    "            player_link = (\n",
    "                player_link_elements[0].get_attribute(\"href\")\n",
    "                if player_link_elements\n",
    "                else None\n",
    "            )\n",
    "\n",
    "            # Extract other data columns\n",
    "            row_data = [col.text.strip() for col in columns]\n",
    "            row_data.append(team_name)  # Append team name\n",
    "            row_data.append(player_link)  # Append player link\n",
    "            row_data.append(season)  # Append season\n",
    "\n",
    "            data.append(row_data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# Usage of the function\n",
    "all_rosters = process_batches(team_stats, batch_size=2, type=1)\n",
    "\n",
    "# Write the data to CSV\n",
    "csv_file_name = \"nba_roster_1.csv\"\n",
    "\n",
    "header = [\n",
    "    \"Player\",\n",
    "    \"#\",\n",
    "    \"Pos\",\n",
    "    \"Height\",\n",
    "    \"Weight\",\n",
    "    \"Birthdate\",\n",
    "    \"Age\",\n",
    "    \"Exp\",\n",
    "    \"School\",\n",
    "    \"How Acquired\",\n",
    "    \"Team Name\",\n",
    "    \"Player Link\",\n",
    "    \"Season\",\n",
    "]\n",
    "\n",
    "\n",
    "with open(csv_file_name, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(header)  # Write header row\n",
    "    writer.writerows(all_rosters)  # Write roster rows\n",
    "\n",
    "print(f\"Roster data saved to {csv_file_name}\")\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Player stat total**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "url = \"https://www.nba.com/stats/leaders\"\n",
    "url_season = [\n",
    "    \"?Season=2024-25\",\n",
    "    \"?Season=2023-24\",\n",
    "    \"?Season=2022-23\",\n",
    "    \"?Season=2021-22\",\n",
    "    \"?Season=2020-21\",\n",
    "]\n",
    "\n",
    "data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in url_season:\n",
    "    driver.get(url + i)\n",
    "    time.sleep(2)  # Allow the page to load\n",
    "\n",
    "    # Wait for the pagination element to appear\n",
    "    try:\n",
    "        pagination = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (By.XPATH, '//div[contains(@class, \"Pagination_content\")]')\n",
    "            )\n",
    "        )\n",
    "        page = int(pagination.find_element(By.XPATH, \".//div[4]\").text.split(\" \")[-1])\n",
    "    except Exception as e:\n",
    "        print(f\"Pagination element not found: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Locate table headers\n",
    "    headers = driver.find_element(By.XPATH, '//tr[contains(@class, \"Crom_headers\")]')\n",
    "    columns = [header.text for header in headers.find_elements(By.TAG_NAME, \"th\")]\n",
    "    columns.append(\"Season\")  # Add a season column\n",
    "\n",
    "    # Temporary DataFrame for the current season\n",
    "    season_data = pd.DataFrame(columns=columns)\n",
    "\n",
    "    for _ in range(page):\n",
    "        # Locate table rows\n",
    "        table = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (By.XPATH, '//tbody[contains(@class, \"Crom_body\")]')\n",
    "            )\n",
    "        )\n",
    "        rows = table.find_elements(By.XPATH, \".//tr\")\n",
    "\n",
    "        for row in rows:\n",
    "            cells = row.find_elements(By.XPATH, \".//td\")\n",
    "            row_data = [cell.text for cell in cells]\n",
    "            if row_data:  # Avoid empty rows\n",
    "                row_data.append(i.split(\"=\")[-1])  # Add the season\n",
    "                season_data.loc[len(season_data)] = row_data\n",
    "\n",
    "        # Click the next page button\n",
    "        try:\n",
    "            button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable(\n",
    "                    (\n",
    "                        By.XPATH,\n",
    "                        './/button[@type=\"button\" and @title=\"Next Page Button\"]',\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            driver.execute_script(\n",
    "                \"arguments[0].click();\", button\n",
    "            )  # Ensure no overlay blocks the click\n",
    "            time.sleep(3)  # Wait for the next page to load\n",
    "        except Exception as e:\n",
    "            print(f\"Pagination error: {e}\")\n",
    "            break\n",
    "\n",
    "    # Append the season's data to the main DataFrame\n",
    "    data = pd.concat([data, season_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "path = \"../../Data_NBA_1/nba_stats.csv\"\n",
    "data.to_csv(path, index=False, header=True)\n",
    "print(f\"Data saved to {path}\")\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Team's Profile**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target URL for NBA Teams page\n",
    "nba_url = \"https://www.nba.com/teams\"\n",
    "\n",
    "# CSV file name to store the team data\n",
    "csv_file_name = \"teams_NBA.csv\"\n",
    "\n",
    "try:\n",
    "    with open(csv_file_name, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "\n",
    "        # Write the header row for the CSV\n",
    "        csv_writer.writerow(\n",
    "            [\"Division\", \"Team Name\", \"Team Profile\", \"Team Stats\", \"Team Schedule\"]\n",
    "        )\n",
    "\n",
    "        driver.get(nba_url)\n",
    "\n",
    "        # Wait for the page to load completely\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (By.CLASS_NAME, \"TeamDivisions_wrapper__5_SVo\")\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Locate all team divisions\n",
    "        divisions = driver.find_elements(By.CLASS_NAME, \"TeamDivisions_division__u3KUS\")\n",
    "\n",
    "        for division in divisions:\n",
    "            division_name = division.find_element(\n",
    "                By.CLASS_NAME, \"TeamDivisions_divisionName__KFlSk\"\n",
    "            ).text\n",
    "            print(f\"Division: {division_name}\")\n",
    "\n",
    "            # Locate teams within the division\n",
    "            teams = division.find_elements(By.CLASS_NAME, \"TeamFigure_tf__jA5HW\")\n",
    "            for team in teams:\n",
    "                team_name = team.find_element(\n",
    "                    By.CLASS_NAME, \"TeamFigure_tfMainLink__OPLFu\"\n",
    "                ).text\n",
    "\n",
    "                # Get URLs for Profile, Stats, and Schedule\n",
    "                team_links = team.find_elements(\n",
    "                    By.CLASS_NAME, \"TeamFigureLink_teamFigureLink__uqnNO\"\n",
    "                )\n",
    "                team_profile = (\n",
    "                    team_links[0].get_attribute(\"href\")\n",
    "                    if len(team_links) > 0\n",
    "                    else \"N/A\"\n",
    "                )\n",
    "                team_stats = (\n",
    "                    team_links[1].get_attribute(\"href\")\n",
    "                    if len(team_links) > 1\n",
    "                    else \"N/A\"\n",
    "                )\n",
    "                team_schedule = (\n",
    "                    team_links[2].get_attribute(\"href\")\n",
    "                    if len(team_links) > 2\n",
    "                    else \"N/A\"\n",
    "                )\n",
    "\n",
    "                print(f\"  Team: {team_name}\")\n",
    "                print(f\"    Profile: {team_profile}\")\n",
    "                print(f\"    Stats: {team_stats}\")\n",
    "                print(f\"    Schedule: {team_schedule}\")\n",
    "\n",
    "                # Write the team data into the CSV\n",
    "                csv_writer.writerow(\n",
    "                    [division_name, team_name, team_profile, team_stats, team_schedule]\n",
    "                )\n",
    "\n",
    "finally:\n",
    "    driver.quit()  # Ensure driver quits even if an error occurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Team's stat total**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_name = \"teams_NBA.csv\"\n",
    "team_profile_list = []\n",
    "team_stats = []\n",
    "\n",
    "url_season = [\n",
    "    \"?Season=2024-25\",\n",
    "    \"?Season=2023-24\",\n",
    "    \"?Season=2022-23\",\n",
    "    \"?Season=2021-22\",\n",
    "    \"?Season=2020-21\",\n",
    "]\n",
    "\n",
    "with open(csv_file_name, mode=\"r\", encoding=\"utf-8\") as csv_file:\n",
    "    reader = csv.DictReader(csv_file)\n",
    "    for row in reader:\n",
    "        team_profile_list.append(row[\"Team Profile\"])\n",
    "        for season_query in url_season:\n",
    "            team_stats.append(row[\"Team Stats\"] + season_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Basketball Reference**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://www.basketball-reference.com/\"\n",
    "service = Service('C:\\Program Files\\WebDriver\\msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Player's profile**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_players():\n",
    "    data = []\n",
    "    for i in range(ord('a'), ord('z') + 1):\n",
    "        letter = chr(i)\n",
    "        print(f\"Crawling in {letter}\")\n",
    "        # Initialize ME browser\n",
    "        driver = webdriver.Edge(service=service)\n",
    "        # Construct the URL for each year\n",
    "        url = f\"{BASE_URL}/players/{letter}\"\n",
    "        driver.get(url)\n",
    "\n",
    "        try:\n",
    "            players = driver.find_elements(By.XPATH, \"//table[@id='players']/tbody/tr\") \n",
    "            for player in players: \n",
    "                retired = 1\n",
    "                try:\n",
    "                    name = player.find_element(By.XPATH, \"./th/strong/a\").text.replace('*', '')\n",
    "                    retired = 0\n",
    "                except:\n",
    "                    try:\n",
    "                        name = player.find_element(By.XPATH, \"./th/a\").text.replace('*', '')\n",
    "                    except:\n",
    "                        continue\n",
    "        \n",
    "                from_year = player.find_element(By.XPATH, \"./td[1]\").text \n",
    "                to_year = player.find_element(By.XPATH, \"./td[2]\").text \n",
    "                pos = player.find_element(By.XPATH, \"./td[3]\").text \n",
    "                height = player.find_element(By.XPATH, \"./td[4]\").text \n",
    "                weight = player.find_element(By.XPATH, \"./td[5]\").text \n",
    "                birth_date = player.find_element(By.XPATH, \"./td[6]\").text \n",
    "                colleges = player.find_element(By.XPATH, \"./td[7]\").text \n",
    "            \n",
    "                data.append([name, from_year, to_year, pos, height, weight, birth_date, colleges, retired]) \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            driver.quit()\n",
    "            break\n",
    "\n",
    "        # Đóng trình duyệt\n",
    "        driver.quit()\n",
    "\n",
    "    # Tạo DataFrame và lưu vào file CSV \n",
    "    df = pd.DataFrame(data, columns=[\"Name\", \"From\", \"To\", \"Pos\", \"Height\", \"Weight\", \"Birth Date\", \"Colleges\", \"Retired\"]) \n",
    "    df.to_csv(\"players_data.csv\", index=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = get_players()\n",
    "df.to_csv(\"player_profile.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Player's total stats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_links():\n",
    "    links = []\n",
    "    for i in range(ord('a'), ord('z') + 1):\n",
    "        letter = chr(i)\n",
    "        print(f\"Crawling in {letter}\")\n",
    "    \n",
    "        # Construct the URL for each year\n",
    "        url = f\"{BASE_URL}/players/{letter}\"\n",
    "        driver.get(url)\n",
    "\n",
    "        try:\n",
    "            players = driver.find_elements(By.XPATH, \"//table[@id='players']/tbody/tr\") \n",
    "            for player in players: \n",
    "                try:\n",
    "                    profile_link = player.find_element(By.XPATH, \"./th/strong/a\").get_attribute(\"href\")\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "                links.append(profile_link) \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            driver.quit()\n",
    "            break\n",
    "\n",
    "        # Đóng trình duyệt\n",
    "        driver.quit()\n",
    "    \n",
    "    return links\n",
    "\n",
    "player_active_links = get_player_links()\n",
    "with open(\"links.txt\", \"w\") as file:\n",
    "    for item in player_active_links:\n",
    "        file.write(item + \"\\n\")\n",
    "\n",
    "def get_player_stats():\n",
    "    data = []\n",
    "    \n",
    "    with open(\"links.txt\", \"r\") as file:\n",
    "        for line in file:\n",
    "            url = line.strip()\n",
    "            \n",
    "            driver = webdriver.Edge(service=service)\n",
    "            # Mở trang web\n",
    "            driver.get(url)\n",
    "            \n",
    "            try:\n",
    "                # Lấy dữ liệu từ bảng \"totals\"\n",
    "                totals_table = driver.find_element(By.XPATH, \"//table[@id='totals_stats']\")\n",
    "                rows = totals_table.find_elements(By.XPATH, \".//tbody/tr\")\n",
    "                \n",
    "                name = driver.find_element(By.ID, \"meta\").find_elements(By.TAG_NAME, \"div\")[1].find_element(By.TAG_NAME, \"h1\").text\n",
    "\n",
    "                for row in rows:\n",
    "                    try:\n",
    "                        season = row.find_element(By.XPATH, \"./th\").text\n",
    "                        team = row.find_element(By.XPATH, \"./td[2]\").text\n",
    "                        pos = row.find_element(By.XPATH, \"./td[4]\").text\n",
    "                        g = row.find_element(By.XPATH, \"./td[5]\").text\n",
    "                        gs = row.find_element(By.XPATH, \"./td[6]\").text\n",
    "                        mp = row.find_element(By.XPATH, \"./td[7]\").text\n",
    "                        fg = row.find_element(By.XPATH, \"./td[8]\").text\n",
    "                        fga = row.find_element(By.XPATH, \"./td[9]\").text\n",
    "                        fg_pct = row.find_element(By.XPATH, \"./td[10]\").text\n",
    "                        fg3 = row.find_element(By.XPATH, \"./td[11]\").text\n",
    "                        fg3a = row.find_element(By.XPATH, \"./td[12]\").text\n",
    "                        fg3_pct = row.find_element(By.XPATH, \"./td[13]\").text\n",
    "                        fg2 = row.find_element(By.XPATH, \"./td[14]\").text\n",
    "                        fg2a = row.find_element(By.XPATH, \"./td[15]\").text\n",
    "                        fg2_pct = row.find_element(By.XPATH, \"./td[16]\").text\n",
    "                        efg_pct = row.find_element(By.XPATH, \"./td[17]\").text\n",
    "                        ft = row.find_element(By.XPATH, \"./td[18]\").text\n",
    "                        fta = row.find_element(By.XPATH, \"./td[19]\").text\n",
    "                        ft_pct = row.find_element(By.XPATH, \"./td[20]\").text\n",
    "                        orb = row.find_element(By.XPATH, \"./td[21]\").text\n",
    "                        drb = row.find_element(By.XPATH, \"./td[22]\").text\n",
    "                        trb = row.find_element(By.XPATH, \"./td[23]\").text\n",
    "                        ast = row.find_element(By.XPATH, \"./td[24]\").text\n",
    "                        stl = row.find_element(By.XPATH, \"./td[25]\").text\n",
    "                        blk = row.find_element(By.XPATH, \"./td[26]\").text\n",
    "                        tov = row.find_element(By.XPATH, \"./td[27]\").text\n",
    "                        pf = row.find_element(By.XPATH, \"./td[28]\").text\n",
    "                        pts = row.find_element(By.XPATH, \"./td[29]\").text\n",
    "                        \n",
    "                        data.append([season, team, pos, g, gs, mp, fg, fga, fg_pct, fg3, fg3a, fg3_pct, fg2, fg2a, fg2_pct, efg_pct, ft, fta, ft_pct, orb, drb, trb, ast, stl, blk, tov, pf, pts, name])\n",
    "                    except:\n",
    "                        continue\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                driver.quit()\n",
    "                break\n",
    "            # Đóng trình duyệt\n",
    "            driver.quit()\n",
    "\n",
    "    # Tạo DataFrame và thêm cột \"Name\"\n",
    "    df = pd.DataFrame(data, columns=[\"Season\", \"Team\", \"Pos\", \"G\", \"GS\", \"MP\", \"FG\", \"FGA\", \"FG%\", \"3P\", \"3PA\", \"3P%\", \"2P\", \"2PA\", \"2P%\", \"eFG%\", \"FT\", \"FTA\", \"FT%\", \"ORB\", \"DRB\", \"TRB\", \"AST\", \"STL\", \"BLK\", \"TOV\", \"PF\", \"PTS\", \"Name\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "df = get_player_stats()\n",
    "df.to_csv(\"totals_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Player's per game stats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_stats_pg():\n",
    "    data = []\n",
    "    \n",
    "    with open(\"links.txt\", \"r\") as file:\n",
    "        for line in file:\n",
    "            url = line.strip()\n",
    "            \n",
    "            driver = webdriver.Edge(service=service)\n",
    "            # Mở trang web\n",
    "            driver.get(url)\n",
    "            \n",
    "            try:\n",
    "                totals_table = driver.find_element(By.XPATH, \"//table[@id='per_game_stats']\")\n",
    "                rows = totals_table.find_elements(By.XPATH, \".//tbody/tr\")\n",
    "                \n",
    "                name = driver.find_element(By.ID, \"meta\").find_elements(By.TAG_NAME, \"div\")[1].find_element(By.TAG_NAME, \"h1\").text\n",
    "\n",
    "                for row in rows:\n",
    "                    try:\n",
    "                        season = row.find_element(By.XPATH, \"./th\").text\n",
    "                        team = row.find_element(By.XPATH, \"./td[2]\").text\n",
    "                        pos = row.find_element(By.XPATH, \"./td[4]\").text\n",
    "                        g = row.find_element(By.XPATH, \"./td[5]\").text\n",
    "                        gs = row.find_element(By.XPATH, \"./td[6]\").text\n",
    "                        mp = row.find_element(By.XPATH, \"./td[7]\").text\n",
    "                        fg = row.find_element(By.XPATH, \"./td[8]\").text\n",
    "                        fga = row.find_element(By.XPATH, \"./td[9]\").text\n",
    "                        fg_pct = row.find_element(By.XPATH, \"./td[10]\").text\n",
    "                        fg3 = row.find_element(By.XPATH, \"./td[11]\").text\n",
    "                        fg3a = row.find_element(By.XPATH, \"./td[12]\").text\n",
    "                        fg3_pct = row.find_element(By.XPATH, \"./td[13]\").text\n",
    "                        fg2 = row.find_element(By.XPATH, \"./td[14]\").text\n",
    "                        fg2a = row.find_element(By.XPATH, \"./td[15]\").text\n",
    "                        fg2_pct = row.find_element(By.XPATH, \"./td[16]\").text\n",
    "                        efg_pct = row.find_element(By.XPATH, \"./td[17]\").text\n",
    "                        ft = row.find_element(By.XPATH, \"./td[18]\").text\n",
    "                        fta = row.find_element(By.XPATH, \"./td[19]\").text\n",
    "                        ft_pct = row.find_element(By.XPATH, \"./td[20]\").text\n",
    "                        orb = row.find_element(By.XPATH, \"./td[21]\").text\n",
    "                        drb = row.find_element(By.XPATH, \"./td[22]\").text\n",
    "                        trb = row.find_element(By.XPATH, \"./td[23]\").text\n",
    "                        ast = row.find_element(By.XPATH, \"./td[24]\").text\n",
    "                        stl = row.find_element(By.XPATH, \"./td[25]\").text\n",
    "                        blk = row.find_element(By.XPATH, \"./td[26]\").text\n",
    "                        tov = row.find_element(By.XPATH, \"./td[27]\").text\n",
    "                        pf = row.find_element(By.XPATH, \"./td[28]\").text\n",
    "                        pts = row.find_element(By.XPATH, \"./td[29]\").text\n",
    "                        \n",
    "                        data.append([season, team, pos, g, gs, mp, fg, fga, fg_pct, fg3, fg3a, fg3_pct, fg2, fg2a, fg2_pct, efg_pct, ft, fta, ft_pct, orb, drb, trb, ast, stl, blk, tov, pf, pts, name])\n",
    "                    except:\n",
    "                        continue\n",
    "            \n",
    "            \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                driver.quit()\n",
    "                break\n",
    "            \n",
    "            driver.quit()\n",
    "    # Tạo DataFrame và thêm cột \"Name\"\n",
    "    df = pd.DataFrame(data, columns=[\"Season\", \"Team\", \"Pos\", \"G\", \"GS\", \"MP\", \"FG\", \"FGA\", \"FG%\", \"3P\", \"3PA\", \"3P%\", \"2P\", \"2PA\", \"2P%\", \"eFG%\", \"FT\", \"FTA\", \"FT%\", \"ORB\", \"DRB\", \"TRB\", \"AST\", \"STL\", \"BLK\", \"TOV\", \"PF\", \"PTS\", \"Name\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "df = get_player_stats_pg()\n",
    "df.to_csv(\"player_stats_per_game.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Team's total stats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(year_interval: str='2020:2022', div_id: str='totals_team'):\n",
    "    all_data = []\n",
    "    start_year, end_year = year_interval.split(':')\n",
    "    for year in range(int(start_year), int(end_year) + 1):\n",
    "        # Initialize ME browser\n",
    "        driver = webdriver.Edge(service=service)\n",
    "        # Construct the URL for each year\n",
    "        url = f\"{BASE_URL}leagues/NBA_{year}.html\"\n",
    "        driver.get(url)\n",
    "        \n",
    "        try: \n",
    "            tbl = driver.find_element(By.ID, div_id)\n",
    "        except Exception:\n",
    "            driver.quit()\n",
    "            continue\n",
    "        \n",
    "        # Extract column names\n",
    "        header = tbl.find_element(By.TAG_NAME, 'thead')\n",
    "        cols = header.text.strip().split(' ')\n",
    "\n",
    "        rows = tbl.find_element(By.TAG_NAME, 'tbody')\n",
    "        data_rows = rows.find_elements(By.TAG_NAME, 'tr')\n",
    "        teams, Gs, MPs, FGs, FGAs, FGPs, thPs, thPAs, thPPs, tPs, tPAs, tPPs, FTs, FTAs, FTPs, ORBs, DRBs, TRBs, ASTs, STLs, BLKs, TOVs, PFs, PTSs  = [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []\n",
    "        ranks = []\n",
    "        # Extract data\n",
    "        for row in data_rows:\n",
    "            try:\n",
    "                rank = row.find_element(By.TAG_NAME, 'th').text\n",
    "                rank = int(rank)\n",
    "            except:\n",
    "                continue\n",
    "            ranks.append(rank)\n",
    "            \n",
    "            stats = row.find_elements(By.TAG_NAME, 'td')\n",
    "            teams.append(stats[0].text.replace('*',''))\n",
    "            Gs.append(stats[1].text)\n",
    "            MPs.append(stats[2].text)\n",
    "            FGs.append(stats[3].text)\n",
    "            FGAs.append(stats[4].text)\n",
    "            FGPs.append(stats[5].text)\n",
    "            thPs.append(stats[6].text)\n",
    "            thPAs.append(stats[7].text)\n",
    "            thPPs.append(stats[8].text)\n",
    "            tPs.append(stats[9].text)\n",
    "            tPAs.append(stats[10].text)\n",
    "            tPPs.append(stats[11].text)\n",
    "            FTs.append(stats[12].text)\n",
    "            FTAs.append(stats[13].text)\n",
    "            FTPs.append(stats[14].text)\n",
    "            ORBs.append(stats[15].text)\n",
    "            DRBs.append(stats[16].text)\n",
    "            TRBs.append(stats[17].text)\n",
    "            ASTs.append(stats[18].text)\n",
    "            STLs.append(stats[19].text)\n",
    "            BLKs.append(stats[20].text)\n",
    "            TOVs.append(stats[21].text)\n",
    "            PFs.append(stats[22].text)\n",
    "            PTSs.append(stats[23].text)\n",
    "            \n",
    "        driver.quit()\n",
    "        \n",
    "        # Create a DataFrame for the current year\n",
    "        data = list(zip(ranks, teams, Gs, MPs, FGs, FGAs, FGPs, thPs, thPAs, thPPs, tPs, tPAs, tPPs, FTs, FTAs, FTPs, ORBs, DRBs, TRBs, ASTs, STLs, BLKs, TOVs, PFs, PTSs))\n",
    "        df_year = pd.DataFrame(data, columns=cols)\n",
    "        df_year['Season'] = f\"{year - 1}-{year}\"  # Add a column for the year\n",
    "        \n",
    "        # Append the year data to the all_data list\n",
    "        all_data.append(df_year)\n",
    "\n",
    "    # Concatenate all the data frames\n",
    "    final_df = pd.concat(all_data, axis=0, ignore_index=True)\n",
    "\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "totals_df = get_stats('2024:2025', 'totals-team')\n",
    "totals_df.to_csv(\"total_stats.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Team's per game stats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgs_df = get_stats('1995:2024', 'per_game-team')\n",
    "pgs_df.to_csv(\"per_game_stats.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rookies' info**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rookies(start_year, end_year):\n",
    "    data = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        print(f\"Crawling in {year}\")\n",
    "        service = Service('C:\\Program Files\\WebDriver\\msedgedriver.exe')\n",
    "        # Initialize ME browser\n",
    "        driver = webdriver.Edge(service=service)\n",
    "        # Construct the URL for each year\n",
    "        url = f\"{BASE_URL}/leagues/NBA_{year}_rookies-career-stats.html\"\n",
    "        driver.get(url)\n",
    "\n",
    "        try: \n",
    "            # Lấy dữ liệu từ bảng\n",
    "            table = driver.find_element(By.ID, \"rookies\")\n",
    "            rows = table.find_element(By.TAG_NAME, \"tbody\").find_elements(By.CLASS_NAME, \"full_table\")\n",
    "            rank = 1\n",
    "            season = f'{year - 1}-{year}'\n",
    "            \n",
    "            for row in rows:\n",
    "                cols = row.find_elements(By.TAG_NAME, \"td\") \n",
    "                cols = [col.text for col in cols] \n",
    "                cols.insert(0, rank)\n",
    "                cols.insert(0, season)\n",
    "                data.append(cols)\n",
    "                rank += 1\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "        # Đóng trình duyệt\n",
    "        driver.quit()\n",
    "\n",
    "    # Tạo DataFrame và lưu vào file CSV\n",
    "    df = pd.DataFrame(data, columns=[\"Season\", \"Rank\", \"Player\", \"Debut\", \"Age\", \"Yrs\", \"G\", \"MP\", \"FG\", \"FGA\", \"3P\", \"3PA\", \"FT\", \"FTA\", \"ORB\", \"TRB\", \"AST\", \"STL\", \"BLK\", \"TOV\", \"PF\", \"PTS\", \"FG%\", \"3P%\", \"FT%\", \"MP (Per Game)\", \"PTS (Per Game)\", \"TRB (Per Game)\", \"AST (Per Game)\", \"STL (Per Game)\", \"BLK (Per Game)\"])\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = get_rookies(2015, 2015)\n",
    "df.to_csv(\"rookies_stats.csv\", index=False, header=False)\n",
    "print(\"Dữ liệu đã được lưu vào file rookies_stats.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
