{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import time\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Division: ATLANTIC\n",
      "  Team: Boston Celtics\n",
      "    Profile: https://www.nba.com/team/1610612738/celtics/\n",
      "    Stats: https://www.nba.com/stats/team/1610612738\n",
      "    Schedule: https://www.nba.com/celtics/schedule\n",
      "  Team: Brooklyn Nets\n",
      "    Profile: https://www.nba.com/team/1610612751/nets/\n",
      "    Stats: https://www.nba.com/stats/team/1610612751\n",
      "    Schedule: https://www.nba.com/nets/schedule\n",
      "  Team: New York Knicks\n",
      "    Profile: https://www.nba.com/team/1610612752/knicks/\n",
      "    Stats: https://www.nba.com/stats/team/1610612752\n",
      "    Schedule: https://www.nba.com/knicks/schedule\n",
      "  Team: Philadelphia 76ers\n",
      "    Profile: https://www.nba.com/team/1610612755/sixers/\n",
      "    Stats: https://www.nba.com/stats/team/1610612755\n",
      "    Schedule: https://www.nba.com/sixers/schedule\n",
      "  Team: Toronto Raptors\n",
      "    Profile: https://www.nba.com/team/1610612761/raptors/\n",
      "    Stats: https://www.nba.com/stats/team/1610612761\n",
      "    Schedule: https://www.nba.com/raptors/schedule\n",
      "Division: CENTRAL\n",
      "  Team: Chicago Bulls\n",
      "    Profile: https://www.nba.com/team/1610612741/bulls/\n",
      "    Stats: https://www.nba.com/stats/team/1610612741\n",
      "    Schedule: https://www.nba.com/bulls/schedule\n",
      "  Team: Cleveland Cavaliers\n",
      "    Profile: https://www.nba.com/team/1610612739/cavaliers/\n",
      "    Stats: https://www.nba.com/stats/team/1610612739\n",
      "    Schedule: https://www.nba.com/cavaliers/schedule\n",
      "  Team: Detroit Pistons\n",
      "    Profile: https://www.nba.com/team/1610612765/pistons/\n",
      "    Stats: https://www.nba.com/stats/team/1610612765\n",
      "    Schedule: https://www.nba.com/pistons/schedule\n",
      "  Team: Indiana Pacers\n",
      "    Profile: https://www.nba.com/team/1610612754/pacers/\n",
      "    Stats: https://www.nba.com/stats/team/1610612754\n",
      "    Schedule: https://www.nba.com/pacers/schedule\n",
      "  Team: Milwaukee Bucks\n",
      "    Profile: https://www.nba.com/team/1610612749/bucks/\n",
      "    Stats: https://www.nba.com/stats/team/1610612749\n",
      "    Schedule: https://www.nba.com/bucks/schedule\n",
      "Division: SOUTHEAST\n",
      "  Team: Atlanta Hawks\n",
      "    Profile: https://www.nba.com/team/1610612737/hawks/\n",
      "    Stats: https://www.nba.com/stats/team/1610612737\n",
      "    Schedule: https://www.nba.com/hawks/schedule\n",
      "  Team: Charlotte Hornets\n",
      "    Profile: https://www.nba.com/team/1610612766/hornets/\n",
      "    Stats: https://www.nba.com/stats/team/1610612766\n",
      "    Schedule: https://www.nba.com/hornets/schedule\n",
      "  Team: Miami Heat\n",
      "    Profile: https://www.nba.com/team/1610612748/heat/\n",
      "    Stats: https://www.nba.com/stats/team/1610612748\n",
      "    Schedule: https://www.nba.com/heat/schedule\n",
      "  Team: Orlando Magic\n",
      "    Profile: https://www.nba.com/team/1610612753/magic/\n",
      "    Stats: https://www.nba.com/stats/team/1610612753\n",
      "    Schedule: https://www.nba.com/magic/schedule\n",
      "  Team: Washington Wizards\n",
      "    Profile: https://www.nba.com/team/1610612764/wizards/\n",
      "    Stats: https://www.nba.com/stats/team/1610612764\n",
      "    Schedule: https://www.nba.com/wizards/schedule\n",
      "Division: NORTHWEST\n",
      "  Team: Denver Nuggets\n",
      "    Profile: https://www.nba.com/team/1610612743/nuggets/\n",
      "    Stats: https://www.nba.com/stats/team/1610612743\n",
      "    Schedule: https://www.nba.com/nuggets/schedule\n",
      "  Team: Minnesota Timberwolves\n",
      "    Profile: https://www.nba.com/team/1610612750/timberwolves/\n",
      "    Stats: https://www.nba.com/stats/team/1610612750\n",
      "    Schedule: https://www.nba.com/timberwolves/schedule\n",
      "  Team: Oklahoma City Thunder\n",
      "    Profile: https://www.nba.com/team/1610612760/thunder/\n",
      "    Stats: https://www.nba.com/stats/team/1610612760\n",
      "    Schedule: https://www.nba.com/thunder/schedule\n",
      "  Team: Portland Trail Blazers\n",
      "    Profile: https://www.nba.com/team/1610612757/blazers/\n",
      "    Stats: https://www.nba.com/stats/team/1610612757\n",
      "    Schedule: https://www.nba.com/blazers/schedule\n",
      "  Team: Utah Jazz\n",
      "    Profile: https://www.nba.com/team/1610612762/jazz/\n",
      "    Stats: https://www.nba.com/stats/team/1610612762\n",
      "    Schedule: https://www.nba.com/jazz/schedule\n",
      "Division: PACIFIC\n",
      "  Team: Golden State Warriors\n",
      "    Profile: https://www.nba.com/team/1610612744/warriors/\n",
      "    Stats: https://www.nba.com/stats/team/1610612744\n",
      "    Schedule: https://www.nba.com/warriors/schedule\n",
      "  Team: LA Clippers\n",
      "    Profile: https://www.nba.com/team/1610612746/clippers/\n",
      "    Stats: https://www.nba.com/stats/team/1610612746\n",
      "    Schedule: https://www.nba.com/clippers/schedule\n",
      "  Team: Los Angeles Lakers\n",
      "    Profile: https://www.nba.com/team/1610612747/lakers/\n",
      "    Stats: https://www.nba.com/stats/team/1610612747\n",
      "    Schedule: https://www.nba.com/lakers/schedule\n",
      "  Team: Phoenix Suns\n",
      "    Profile: https://www.nba.com/team/1610612756/suns/\n",
      "    Stats: https://www.nba.com/stats/team/1610612756\n",
      "    Schedule: https://www.nba.com/suns/schedule\n",
      "  Team: Sacramento Kings\n",
      "    Profile: https://www.nba.com/team/1610612758/kings/\n",
      "    Stats: https://www.nba.com/stats/team/1610612758\n",
      "    Schedule: https://www.nba.com/kings/schedule\n",
      "Division: SOUTHWEST\n",
      "  Team: Dallas Mavericks\n",
      "    Profile: https://www.nba.com/team/1610612742/mavericks/\n",
      "    Stats: https://www.nba.com/stats/team/1610612742\n",
      "    Schedule: https://www.nba.com/mavericks/schedule\n",
      "  Team: Houston Rockets\n",
      "    Profile: https://www.nba.com/team/1610612745/rockets/\n",
      "    Stats: https://www.nba.com/stats/team/1610612745\n",
      "    Schedule: https://www.nba.com/rockets/schedule\n",
      "  Team: Memphis Grizzlies\n",
      "    Profile: https://www.nba.com/team/1610612763/grizzlies/\n",
      "    Stats: https://www.nba.com/stats/team/1610612763\n",
      "    Schedule: https://www.nba.com/grizzlies/schedule\n",
      "  Team: New Orleans Pelicans\n",
      "    Profile: https://www.nba.com/team/1610612740/pelicans/\n",
      "    Stats: https://www.nba.com/stats/team/1610612740\n",
      "    Schedule: https://www.nba.com/pelicans/schedule\n",
      "  Team: San Antonio Spurs\n",
      "    Profile: https://www.nba.com/team/1610612759/spurs/\n",
      "    Stats: https://www.nba.com/stats/team/1610612759\n",
      "    Schedule: https://www.nba.com/spurs/schedule\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Target URL for NBA Teams page\n",
    "nba_url = \"https://www.nba.com/teams\"\n",
    "\n",
    "# CSV file name to store the team data\n",
    "csv_file_name = \"teams_NBA.csv\"\n",
    "\n",
    "try:\n",
    "    with open(csv_file_name, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "\n",
    "        # Write the header row for the CSV\n",
    "        csv_writer.writerow(\n",
    "            [\"Division\", \"Team Name\", \"Team Profile\", \"Team Stats\", \"Team Schedule\"]\n",
    "        )\n",
    "\n",
    "        driver.get(nba_url)\n",
    "\n",
    "        # Wait for the page to load completely\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (By.CLASS_NAME, \"TeamDivisions_wrapper__5_SVo\")\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Locate all team divisions\n",
    "        divisions = driver.find_elements(By.CLASS_NAME, \"TeamDivisions_division__u3KUS\")\n",
    "\n",
    "        for division in divisions:\n",
    "            division_name = division.find_element(\n",
    "                By.CLASS_NAME, \"TeamDivisions_divisionName__KFlSk\"\n",
    "            ).text\n",
    "            print(f\"Division: {division_name}\")\n",
    "\n",
    "            # Locate teams within the division\n",
    "            teams = division.find_elements(By.CLASS_NAME, \"TeamFigure_tf__jA5HW\")\n",
    "            for team in teams:\n",
    "                team_name = team.find_element(\n",
    "                    By.CLASS_NAME, \"TeamFigure_tfMainLink__OPLFu\"\n",
    "                ).text\n",
    "\n",
    "                # Get URLs for Profile, Stats, and Schedule\n",
    "                team_links = team.find_elements(\n",
    "                    By.CLASS_NAME, \"TeamFigureLink_teamFigureLink__uqnNO\"\n",
    "                )\n",
    "                team_profile = (\n",
    "                    team_links[0].get_attribute(\"href\")\n",
    "                    if len(team_links) > 0\n",
    "                    else \"N/A\"\n",
    "                )\n",
    "                team_stats = (\n",
    "                    team_links[1].get_attribute(\"href\")\n",
    "                    if len(team_links) > 1\n",
    "                    else \"N/A\"\n",
    "                )\n",
    "                team_schedule = (\n",
    "                    team_links[2].get_attribute(\"href\")\n",
    "                    if len(team_links) > 2\n",
    "                    else \"N/A\"\n",
    "                )\n",
    "\n",
    "                print(f\"  Team: {team_name}\")\n",
    "                print(f\"    Profile: {team_profile}\")\n",
    "                print(f\"    Stats: {team_stats}\")\n",
    "                print(f\"    Schedule: {team_schedule}\")\n",
    "\n",
    "                # Write the team data into the CSV\n",
    "                csv_writer.writerow(\n",
    "                    [division_name, team_name, team_profile, team_stats, team_schedule]\n",
    "                )\n",
    "\n",
    "finally:\n",
    "    driver.quit()  # Ensure driver quits even if an error occurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teams's Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_name = \"teams_NBA.csv\"\n",
    "team_profile_list = []\n",
    "team_stats = []\n",
    "\n",
    "url_season = [\n",
    "    \"?Season=2024-25\",\n",
    "    \"?Season=2023-24\",\n",
    "    \"?Season=2022-23\",\n",
    "    \"?Season=2021-22\",\n",
    "    \"?Season=2020-21\",\n",
    "]\n",
    "\n",
    "with open(csv_file_name, mode=\"r\", encoding=\"utf-8\") as csv_file:\n",
    "    reader = csv.DictReader(csv_file)\n",
    "    for row in reader:\n",
    "        team_profile_list.append(row[\"Team Profile\"])\n",
    "        for season_query in url_season:\n",
    "            team_stats.append(row[\"Team Stats\"] + season_query)\n",
    "\n",
    "team_stats = [\"https://www.nba.com/stats/team/1610612761?Season=2021-22\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process team profiles in batches (2 at a time)\n",
    "def process_batches(team_profile_list, batch_size=2, type=1):\n",
    "    all_rosters = []\n",
    "    # Process the URLs in batches of 2\n",
    "    for i in range(0, len(team_profile_list), batch_size):\n",
    "        batch = team_profile_list[i : i + batch_size]\n",
    "        batch_data = []\n",
    "\n",
    "        # Scrape data for each URL in the current batch\n",
    "        for url in batch:\n",
    "            try:\n",
    "                print(f\"Scraping data for {url}...\")\n",
    "                if type == 1:\n",
    "                    team_roster = scrape_roster(url, url[-7:])\n",
    "                    print(team_roster)\n",
    "                    batch_data.extend(team_roster)\n",
    "                elif type == 2:\n",
    "                    team_retired = scrape_retired(url)\n",
    "                    batch_data.extend(team_retired)\n",
    "                elif type == 3:\n",
    "                    team_hall_of_fame = scrape_hall_of_fame(url)\n",
    "                    batch_data.extend(team_hall_of_fame)\n",
    "                elif type == 4:\n",
    "                    team_all_time_record = scrape_all_time_record(url)\n",
    "                    batch_data.extend(team_all_time_record)\n",
    "                elif type == 5:\n",
    "                    team_achievements = scrape_achievements(url)\n",
    "                    batch_data.extend(team_achievements)\n",
    "                else:\n",
    "                    print(f\"Failed to retrieve roster for {url}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error scraping {url}: {e}\")\n",
    "\n",
    "            # Adding a random sleep between each request to prevent overwhelming the server\n",
    "            sleep(random.uniform(2, 5))\n",
    "\n",
    "        # Once the batch is done, add the data to the all_rosters list\n",
    "        all_rosters.extend(batch_data)\n",
    "\n",
    "        # Wait before processing the next batch to prevent rate-limiting issues\n",
    "        print(f\"Batch of {batch_size} teams processed. Waiting before next batch...\")\n",
    "        time.sleep(10)\n",
    "\n",
    "    return all_rosters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for https://www.nba.com/stats/team/1610612761?Season=2021-22...\n",
      "[['Armoni Brooks', '#1', 'G', '6-3', '195 lbs', 'JUN 05, 1998', '24', '1', 'Houston', '', 'TORONTO RAPTORS', 'https://www.nba.com/stats/player/1629717/', '2021-22'], ['OG Anunoby', '#3', 'F', '6-7', '232 lbs', 'JUL 17, 1997', '24', '4', 'Indiana', '', 'TORONTO RAPTORS', 'https://www.nba.com/stats/player/1628384/', '2021-22'], ['Scottie Barnes', '#4', 'F', '6-7', '225 lbs', 'AUG 01, 2001', '20', 'R', 'Florida State', '#4 Pick in 2021 Draft', 'TORONTO RAPTORS', 'https://www.nba.com/stats/player/1630567/', '2021-22'], ['Precious Achiuwa', '#5', 'F', '6-8', '225 lbs', 'SEP 19, 1999', '22', '1', 'Memphis', '', 'TORONTO RAPTORS', 'https://www.nba.com/stats/player/1630173/', '2021-22'], ['Justin Champagnie', '#11', 'G-F', '6-6', '206 lbs', 'JUN 29, 2001', '21', 'R', 'Pittsburgh', '', 'TORONTO RAPTORS', 'https://www.nba.com/stats/player/1630551/', '2021-22'], ['David Johnson', '#13', 'G', '6-4', '203 lbs', 'FEB 26, 2001', '21', 'R', 'Louisville', '', 'TORONTO RAPTORS', 'https://www.nba.com/stats/player/1630525/', '2021-22'], ['Svi Mykhailiuk', '#14', 'G-F', '6-7', '205 lbs', 'JUN 10, 1997', '25', '3', 'Kansas', '', 'TORONTO RAPTORS', 'https://www.nba.com/stats/player/1629004/', '2021-22'], ['Isaac Bonga', '#17', 'G', '6-8', '180 lbs', 'NOV 08, 1999', '22', '3', 'Skyliners Frankfurt', '', 'TORONTO RAPTORS', 'https://www.nba.com/stats/player/1629067/', '2021-22'], ['Yuta Watanabe', '#18', 'G-F', '6-9', '215 lbs', 'OCT 13, 1994', '27', '3', 'George Washington', '', 'TORONTO RAPTORS', 'https://www.nba.com/stats/player/1629139/', '2021-22'], ['Thaddeus Young', '#21', 'F', '6-8', '235 lbs', 'JUN 21, 1988', '34', '14', 'Georgia Tech', '', 'TORONTO RAPTORS', 'https://www.nba.com/stats/player/201152/', '2021-22'], ['Malachi Flynn', '#22', 'G', '6-1', '175 lbs', 'MAY 09, 1998', '24', '1', 'San Diego State', '', 'TORONTO RAPTORS', 'https://www.nba.com/stats/player/1630201/', '2021-22'], ['Fred VanVleet', '#23', 'G', '6-1', '197 lbs', 'FEB 25, 1994', '28', '5', 'Wichita State', '', 'TORONTO RAPTORS', 'https://www.nba.com/stats/player/1627832/', '2021-22'], ['Khem Birch', '#24', 'C', '6-9', '233 lbs', 'SEP 28, 1992', '29', '4', 'UNLV', '', 'TORONTO RAPTORS', 'https://www.nba.com/stats/player/203920/', '2021-22'], ['Chris Boucher', '#25', 'F-C', '6-9', '200 lbs', 'JAN 11, 1993', '29', '4', 'Oregon', 'Signed on 07/20/18', 'TORONTO RAPTORS', 'https://www.nba.com/stats/player/1628449/', '2021-22'], ['Gary Trent Jr.', '#33', 'G-F', '6-5', '209 lbs', 'JAN 18, 1999', '23', '3', 'Duke', '', 'TORONTO RAPTORS', 'https://www.nba.com/stats/player/1629018/', '2021-22'], ['Pascal Siakam', '#43', 'F', '6-8', '230 lbs', 'APR 02, 1994', '28', '5', 'New Mexico State', '', 'TORONTO RAPTORS', 'https://www.nba.com/stats/player/1627783/', '2021-22'], ['Dalano Banton', '#45', 'F', '6-7', '204 lbs', 'NOV 07, 1999', '22', 'R', 'Nebraska', '', 'TORONTO RAPTORS', 'https://www.nba.com/stats/player/1630625/', '2021-22']]\n",
      "Batch of 2 teams processed. Waiting before next batch...\n",
      "Roster data saved to nba_roster_1.csv\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "# Function to scrape the team roster data\n",
    "\n",
    "\n",
    "def scrape_roster(url, season):\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(2)  # Wait for the page to load completely\n",
    "\n",
    "    # Wait for the team name section to load\n",
    "    try:\n",
    "        team_name_section = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"TeamHeader_name__MmHlP\"))\n",
    "        )\n",
    "    except:\n",
    "        print(f\"Unable to load the team name for {url}\")\n",
    "        return []\n",
    "\n",
    "    # Extract team name\n",
    "    team_name_parts = team_name_section.find_elements(By.TAG_NAME, \"div\")\n",
    "    team_name = \" \".join(\n",
    "        [part.text.strip() for part in team_name_parts if part.text.strip()]\n",
    "    )\n",
    "\n",
    "    # Wait for the Roster section to load completely\n",
    "    try:\n",
    "        rows_section = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"Crom_body__UYOcU\"))\n",
    "        )\n",
    "    except:\n",
    "        print(f\"Unable to load the roster section for {team_name}\")\n",
    "        return []\n",
    "\n",
    "    # Extract header for the CSV file\n",
    "    header = [\n",
    "        \"Player\",\n",
    "        \"No.\",\n",
    "        \"Pos\",\n",
    "        \"Height\",\n",
    "        \"Weight\",\n",
    "        \"Birthdate\",\n",
    "        \"Age\",\n",
    "        \"Exp\",\n",
    "        \"School\",\n",
    "        \"How Acquired\",\n",
    "        \"Team Name\",\n",
    "        \"Player Link\",\n",
    "        \"Season\",\n",
    "    ]\n",
    "\n",
    "    # Store the roster data\n",
    "    data = []\n",
    "\n",
    "    # Find all rows in the roster table\n",
    "    rows = rows_section.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "    for row in rows:\n",
    "        columns = row.find_elements(By.TAG_NAME, \"td\")\n",
    "\n",
    "        # Ensure row has data columns\n",
    "        if len(columns) > 0:\n",
    "            player_name = columns[0].text.strip()\n",
    "            player_link_elements = columns[0].find_elements(By.TAG_NAME, \"a\")\n",
    "            player_link = (\n",
    "                player_link_elements[0].get_attribute(\"href\")\n",
    "                if player_link_elements\n",
    "                else None\n",
    "            )\n",
    "\n",
    "            # Extract other data columns\n",
    "            row_data = [col.text.strip() for col in columns]\n",
    "            row_data.append(team_name)  # Append team name\n",
    "            row_data.append(player_link)  # Append player link\n",
    "            row_data.append(season)  # Append season\n",
    "\n",
    "            data.append(row_data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# Usage of the function\n",
    "\n",
    "\n",
    "all_rosters = process_batches(team_stats, batch_size=2, type=1)\n",
    "\n",
    "\n",
    "\n",
    "# Write the data to CSV\n",
    "\n",
    "\n",
    "csv_file_name = \"nba_roster_1.csv\"\n",
    "\n",
    "\n",
    "header = [\n",
    "    \"Player\",\n",
    "    \"#\",\n",
    "    \"Pos\",\n",
    "    \"Height\",\n",
    "    \"Weight\",\n",
    "    \"Birthdate\",\n",
    "    \"Age\",\n",
    "    \"Exp\",\n",
    "    \"School\",\n",
    "    \"How Acquired\",\n",
    "    \"Team Name\",\n",
    "    \"Player Link\",\n",
    "    \"Season\",\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "with open(csv_file_name, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "\n",
    "    writer = csv.writer(csv_file)\n",
    "\n",
    "    writer.writerow(header)  # Write header row\n",
    "\n",
    "    writer.writerows(all_rosters)  # Write roster rows\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Roster data saved to {csv_file_name}\")\n",
    "\n",
    "\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RETIRED NUMBERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "\n",
    "# Function to scrape the team roster data\n",
    "\n",
    "\n",
    "def scrape_retired(url):\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(5)  # Wait for the page to load completely\n",
    "\n",
    "    # Wait for the team name section to load\n",
    "\n",
    "    try:\n",
    "\n",
    "        team_name_section = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"TeamHeader_name__MmHlP\"))\n",
    "        )\n",
    "\n",
    "        team_name_parts = team_name_section.find_elements(By.TAG_NAME, \"div\")\n",
    "\n",
    "        team_name = \" \".join(\n",
    "            [part.text.strip() for part in team_name_parts if part.text.strip()]\n",
    "        )\n",
    "\n",
    "    except:\n",
    "\n",
    "        print(f\"Unable to load the team name for {url}\")\n",
    "\n",
    "        return []\n",
    "\n",
    "    # Wait for the Roster section to load\n",
    "\n",
    "    try:\n",
    "\n",
    "        rows_section = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (By.CLASS_NAME, \"TeamRetired_content__nb7Qt\")\n",
    "            )\n",
    "        )\n",
    "\n",
    "        rows = rows_section.find_elements(By.XPATH, \".//tr\")\n",
    "\n",
    "    except:\n",
    "\n",
    "        print(f\"Unable to load the roster section for {team_name}\")\n",
    "\n",
    "        return []\n",
    "\n",
    "    # Extract header and data\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for row in rows[1:]:  # Skip header row\n",
    "\n",
    "        columns = row.find_elements(By.TAG_NAME, \"td\")\n",
    "\n",
    "        if len(columns) > 0:\n",
    "\n",
    "            player_link = None\n",
    "\n",
    "            try:\n",
    "\n",
    "                player_link = (\n",
    "                    columns[1].find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "                )\n",
    "            except:\n",
    "\n",
    "                pass  # If no link exists, skip gracefully\n",
    "\n",
    "            row_data = [\n",
    "                team_name,  # Team name\n",
    "                player_link,  # Player link\n",
    "                columns[1].text.strip(),  # Player name\n",
    "                columns[0].text.strip(),  # Jersey #\n",
    "                columns[2].text.strip(),  # Position\n",
    "                columns[3].text.strip(),  # Seasons with team\n",
    "                columns[4].text.strip(),  # Year of induction\n",
    "            ]\n",
    "\n",
    "            data.append(row_data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "all_retired = process_batches(team_profile_list, batch_size=2, type=2)\n",
    "\n",
    "\n",
    "# Write the data to CSV\n",
    "\n",
    "\n",
    "csv_file_name = \"nba_retired.csv\"\n",
    "\n",
    "\n",
    "header = [\n",
    "    \"Team Name\",\n",
    "    \"Player Link\",\n",
    "    \"Player\",\n",
    "    \"#\",\n",
    "    \"Pos\",\n",
    "    \"Seasons With Team\",\n",
    "    \"Year of Induction\",\n",
    "]\n",
    "\n",
    "\n",
    "with open(csv_file_name, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "\n",
    "    writer = csv.writer(csv_file)\n",
    "\n",
    "    writer.writerow(header)  # Write header row\n",
    "\n",
    "    writer.writerows(all_retired)  # Write roster rows\n",
    "\n",
    "\n",
    "print(f\"Roster data saved to {csv_file_name}\")\n",
    "\n",
    "\n",
    "# Close the driver\n",
    "\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hall of Fame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "\n",
    "# Function to scrape Hall of Fame data\n",
    "\n",
    "\n",
    "def scrape_hall_of_fame(url):\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(2)  # Wait for the page to load completely\n",
    "\n",
    "    # Wait for the team name section to load\n",
    "\n",
    "    try:\n",
    "\n",
    "        team_name_section = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"TeamHeader_name__MmHlP\"))\n",
    "        )\n",
    "\n",
    "        team_name_parts = team_name_section.find_elements(By.TAG_NAME, \"div\")\n",
    "\n",
    "        team_name = \" \".join(\n",
    "            [part.text.strip() for part in team_name_parts if part.text.strip()]\n",
    "        )\n",
    "\n",
    "    except:\n",
    "\n",
    "        print(f\"Unable to load the team name for {url}\")\n",
    "\n",
    "        return []\n",
    "\n",
    "    # Wait for the Hall of Fame section to load\n",
    "\n",
    "    try:\n",
    "\n",
    "        hall_of_fame_section = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (By.CLASS_NAME, \"TeamHallOfFame_content__IZSl2\")\n",
    "            )\n",
    "        )\n",
    "\n",
    "        rows = hall_of_fame_section.find_elements(By.XPATH, \".//tr\")\n",
    "\n",
    "    except:\n",
    "\n",
    "        print(f\"Unable to load the Hall of Fame section for {team_name}\")\n",
    "\n",
    "        return []\n",
    "\n",
    "    # Extract Hall of Fame data\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for row in rows[1:]:  # Skip header row\n",
    "\n",
    "        columns = row.find_elements(By.TAG_NAME, \"td\")\n",
    "\n",
    "        if len(columns) > 0:\n",
    "\n",
    "            player_link = None\n",
    "\n",
    "            try:\n",
    "\n",
    "                player_link = (\n",
    "                    columns[0].find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "                )\n",
    "            except:\n",
    "\n",
    "                pass  # If no link exists, skip gracefully\n",
    "\n",
    "            row_data = [\n",
    "                team_name,  # Team name\n",
    "                player_link,  # Player link\n",
    "                columns[0].text.strip(),  # Player name\n",
    "                columns[1].text.strip(),  # Position\n",
    "                columns[2].text.strip(),  # Seasons with team\n",
    "                columns[3].text.strip(),  # Year of induction\n",
    "            ]\n",
    "\n",
    "            data.append(row_data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "all_hall_of_fame = process_batches(team_profile_list, batch_size=2, type=3)\n",
    "\n",
    "\n",
    "# Write the data to CSV\n",
    "\n",
    "\n",
    "csv_file_name = \"nba_hall_of_fame.csv\"\n",
    "\n",
    "\n",
    "header = [\n",
    "    \"Team Name\",\n",
    "    \"Player Link\",\n",
    "    \"Player\",\n",
    "    \"Pos\",\n",
    "    \"Seasons With Team\",\n",
    "    \"Year of Induction\",\n",
    "]\n",
    "\n",
    "\n",
    "with open(csv_file_name, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "\n",
    "    writer = csv.writer(csv_file)\n",
    "\n",
    "    writer.writerow(header)  # Write header row\n",
    "\n",
    "    writer.writerows(all_hall_of_fame)  # Write Hall of Fame rows\n",
    "\n",
    "\n",
    "print(f\"Hall of Fame data saved to {csv_file_name}\")\n",
    "\n",
    "\n",
    "# Close the driver\n",
    "\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All-time records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "\n",
    "# Function to scrape All-Time Record data\n",
    "\n",
    "\n",
    "def scrape_all_time_record(url):\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(5)  # Wait for the page to load completely\n",
    "\n",
    "    # Wait for the team name section to load\n",
    "\n",
    "    try:\n",
    "\n",
    "        team_name_section = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"TeamHeader_name__MmHlP\"))\n",
    "        )\n",
    "\n",
    "        team_name_parts = team_name_section.find_elements(By.TAG_NAME, \"div\")\n",
    "\n",
    "        team_name = \" \".join(\n",
    "            [part.text.strip() for part in team_name_parts if part.text.strip()]\n",
    "        )\n",
    "\n",
    "    except:\n",
    "\n",
    "        print(f\"Unable to load the team name for {url}\")\n",
    "\n",
    "        return []\n",
    "\n",
    "    # Wait for the All-Time Record section to load\n",
    "\n",
    "    try:\n",
    "\n",
    "        records_section = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"TeamRecords_table__0iapO\"))\n",
    "        )\n",
    "\n",
    "        rows = records_section.find_elements(By.XPATH, \".//tr\")\n",
    "\n",
    "    except:\n",
    "\n",
    "        print(f\"Unable to load the All-Time Record section for {team_name}\")\n",
    "\n",
    "        return []\n",
    "\n",
    "    # Extract All-Time Record data\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for row in rows:\n",
    "\n",
    "        columns = row.find_elements(By.TAG_NAME, \"td\")\n",
    "\n",
    "        if len(columns) > 0:\n",
    "\n",
    "            player_link = None\n",
    "\n",
    "            try:\n",
    "\n",
    "                player_link = (\n",
    "                    columns[1].find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "                )\n",
    "            except:\n",
    "\n",
    "                pass  # If no link exists, skip gracefully\n",
    "\n",
    "            row_data = [\n",
    "                team_name,  # Team name\n",
    "                columns[0].text.strip(),  # Record type (e.g., \"Total Points\")\n",
    "                columns[1].text.strip(),  # Player name\n",
    "                player_link,  # Player link\n",
    "                columns[2].text.strip(),  # Stat value\n",
    "            ]\n",
    "\n",
    "            data.append(row_data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "all_time_records = process_batches(team_profile_list, batch_size=2, type=4)\n",
    "\n",
    "\n",
    "# Write the data to CSV\n",
    "\n",
    "\n",
    "csv_file_name = \"nba_all_time_records.csv\"\n",
    "\n",
    "\n",
    "header = [\"Team Name\", \"Record Type\", \"Player\", \"Player Link\", \"Stat Value\"]\n",
    "\n",
    "\n",
    "with open(csv_file_name, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "\n",
    "    writer = csv.writer(csv_file)\n",
    "\n",
    "    writer.writerow(header)  # Write header row\n",
    "\n",
    "    writer.writerows(all_time_records)  # Write All-Time Record rows\n",
    "\n",
    "\n",
    "print(f\"All-Time Record data saved to {csv_file_name}\")\n",
    "\n",
    "\n",
    "# Close the driver\n",
    "\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Achievement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "\n",
    "def scrape_achievements(url):\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(2)  # Wait for the page to load completely\n",
    "\n",
    "    # Wait for the Achievements section to load\n",
    "\n",
    "    try:\n",
    "\n",
    "        awards_sections = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located(\n",
    "                (By.CLASS_NAME, \"TeamAwards_group__XU0o9\")\n",
    "            )\n",
    "        )\n",
    "\n",
    "    except TimeoutException:\n",
    "\n",
    "        print(f\"Unable to load the Achievements section for {url}\")\n",
    "\n",
    "        return []\n",
    "\n",
    "    # Wait for the team name section to load\n",
    "\n",
    "    try:\n",
    "\n",
    "        team_name_section = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"TeamHeader_name__MmHlP\"))\n",
    "        )\n",
    "\n",
    "        team_name_parts = team_name_section.find_elements(By.TAG_NAME, \"div\")\n",
    "\n",
    "        team_name = \" \".join(\n",
    "            [part.text.strip() for part in team_name_parts if part.text.strip()]\n",
    "        )\n",
    "\n",
    "    except:\n",
    "\n",
    "        print(f\"Unable to load the team name for {url}\")\n",
    "\n",
    "        return []\n",
    "\n",
    "    # Extracting Achievements: Championship Wins, Conference Titles, Division Titles\n",
    "\n",
    "    data = []\n",
    "\n",
    "    try:\n",
    "\n",
    "        # Extract each category of awards\n",
    "\n",
    "        for group in awards_sections:\n",
    "\n",
    "            # Extracting the heading (e.g., \"Championship Wins\", \"Conference Titles\", \"Division Titles\")\n",
    "\n",
    "            try:\n",
    "\n",
    "                heading = group.find_element(\n",
    "                    By.CLASS_NAME, \"TeamAwards_heading__BvLNE\"\n",
    "                ).text.strip()\n",
    "\n",
    "            except NoSuchElementException:\n",
    "\n",
    "                print(\"Heading not found in group.\")\n",
    "\n",
    "                continue\n",
    "\n",
    "            # Extracting the list of years under each heading\n",
    "\n",
    "            try:\n",
    "\n",
    "                years_list = group.find_elements(\n",
    "                    By.CLASS_NAME, \"TeamAwards_listItem__rb4hz\"\n",
    "                )\n",
    "\n",
    "                for year in years_list:\n",
    "\n",
    "                    row_data = [team_name, heading, year.text.strip()]\n",
    "\n",
    "                    data.append(row_data)\n",
    "\n",
    "            except NoSuchElementException:\n",
    "\n",
    "                print(f\"No years found for {heading}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        print(f\"Error while processing awards: {e}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# Process the team profiles\n",
    "\n",
    "\n",
    "all_achievements = process_batches(team_profile_list, batch_size=2, type=5)\n",
    "\n",
    "\n",
    "# Write the data to CSV\n",
    "\n",
    "\n",
    "csv_file_name = \"nba_achievements.csv\"\n",
    "\n",
    "\n",
    "header = [\"Team Name\", \"Achievement Type\", \"Year\"]\n",
    "\n",
    "\n",
    "with open(csv_file_name, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "\n",
    "    writer = csv.writer(csv_file)\n",
    "\n",
    "    writer.writerow(header)  # Write header row\n",
    "\n",
    "    writer.writerows(all_achievements)  # Write achievement rows\n",
    "\n",
    "\n",
    "print(f\"Achievement data saved to {csv_file_name}\")\n",
    "\n",
    "\n",
    "# Close the driver\n",
    "\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team's Stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_stats = [team_stat + \"/traditional\" for team_stat in team_stats]\n",
    "\n",
    "team_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "\n",
    "# Function to scrape the table data for a given year\n",
    "\n",
    "\n",
    "def scrape_table_data():\n",
    "\n",
    "    table_data = []\n",
    "\n",
    "    # Wait for the table to load\n",
    "\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"Crom_table__p1iZz\"))\n",
    "    )\n",
    "\n",
    "    # Locate the table\n",
    "\n",
    "    table = driver.find_element(By.CLASS_NAME, \"Crom_table__p1iZz\")\n",
    "\n",
    "    # Extract headers and their titles\n",
    "\n",
    "    headers = table.find_element(By.TAG_NAME, \"thead\").find_elements(By.TAG_NAME, \"th\")\n",
    "\n",
    "    header_data = []\n",
    "\n",
    "    for header in headers:\n",
    "\n",
    "        field = header.get_attribute(\"field\")  # e.g., \"GP\"\n",
    "\n",
    "        title = header.get_attribute(\"title\")  # e.g., \"Game Played\"\n",
    "\n",
    "        header_data.append((field, title))\n",
    "\n",
    "    # Extract rows\n",
    "\n",
    "    body = table.find_element(By.TAG_NAME, \"tbody\")\n",
    "\n",
    "    rows = body.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "    for row in rows:\n",
    "\n",
    "        cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "\n",
    "        row_data = [col.text.strip() for col in cols]\n",
    "\n",
    "        table_data.append(row_data)\n",
    "\n",
    "    return header_data, table_data\n",
    "\n",
    "\n",
    "# Function to get the team name\n",
    "\n",
    "\n",
    "def get_team_name():\n",
    "\n",
    "    try:\n",
    "\n",
    "        team_name_section = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"TeamHeader_name__MmHlP\"))\n",
    "        )\n",
    "\n",
    "        team_name_parts = team_name_section.find_elements(By.TAG_NAME, \"div\")\n",
    "\n",
    "        team_name = \" \".join(\n",
    "            [part.text.strip() for part in team_name_parts if part.text.strip()]\n",
    "        )\n",
    "\n",
    "        return team_name\n",
    "\n",
    "    except:\n",
    "\n",
    "        print(\"Unable to load the team name\")\n",
    "\n",
    "        return \"Unknown Team\"\n",
    "\n",
    "\n",
    "# Main function to scrape all years\n",
    "\n",
    "\n",
    "def scrape_all_years(url):\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(2)  # Wait for the page to load\n",
    "\n",
    "    # Get the team name\n",
    "\n",
    "    team_name = get_team_name()\n",
    "\n",
    "    print(f\"Team Name: {team_name}\")\n",
    "\n",
    "    # Wait for the dropdown to appear\n",
    "\n",
    "    dropdown = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"DropDown_select__4pIg9\"))\n",
    "    )\n",
    "\n",
    "    # Get all options from the dropdown\n",
    "\n",
    "    select = Select(dropdown)\n",
    "\n",
    "    all_years = [\n",
    "        option.get_attribute(\"value\")\n",
    "        for option in select.options\n",
    "        if option.get_attribute(\"value\")\n",
    "    ]\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    # Iterate over each year, select it, and scrape the table data\n",
    "\n",
    "    for year in all_years:\n",
    "\n",
    "        print(f\"Scraping data for year: {year}\")\n",
    "\n",
    "        select.select_by_value(year)\n",
    "\n",
    "        time.sleep(2)  # Allow the page to refresh with the new data\n",
    "\n",
    "        try:\n",
    "\n",
    "            header_data, table_data = scrape_table_data()\n",
    "\n",
    "            # Append the year and team name to the data\n",
    "\n",
    "            for row in table_data:\n",
    "\n",
    "                row.insert(0, year)  # Add year to the start of each row\n",
    "\n",
    "                row.insert(0, team_name)  # Add team name to the start of each row\n",
    "\n",
    "            all_data.extend(table_data)\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            print(f\"Error scraping data for year {year}: {e}\")\n",
    "\n",
    "    return header_data, all_data\n",
    "\n",
    "\n",
    "# Initialize CSV file only once\n",
    "\n",
    "\n",
    "csv_file_name = \"nba_team_stats.csv\"\n",
    "\n",
    "\n",
    "with open(csv_file_name, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write headers later after determining them\n",
    "\n",
    "    header_written = False\n",
    "\n",
    "    # Loop through each URL in the list\n",
    "\n",
    "    for url in team_stats:  # `team_stats` should be a list of URLs\n",
    "\n",
    "        print(f\"Scraping data for URL: {url}\")\n",
    "\n",
    "        try:\n",
    "\n",
    "            # Scrape data for the current URL\n",
    "\n",
    "            header_data, all_data = scrape_all_years(url)\n",
    "\n",
    "            if not header_written:\n",
    "\n",
    "                # Write the headers only once\n",
    "\n",
    "                writer.writerow(\n",
    "                    [\"Team Name\", \"Year\"]\n",
    "                    + [f\"{field} - {title}\" for field, title in header_data]\n",
    "                )\n",
    "\n",
    "                header_written = True\n",
    "\n",
    "            # Write the data rows\n",
    "\n",
    "            writer.writerows(all_data)\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            print(f\"Error scraping data for {url}: {e}\")\n",
    "\n",
    "\n",
    "print(f\"Data saved to {csv_file_name}\")\n",
    "\n",
    "\n",
    "# Close the driver after all URLs are processed\n",
    "\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
