{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from time import sleep\n",
    "\n",
    "# Path to ChromeDriver executable\n",
    "chrome_driver_path = r'D:\\chromedriver-win64\\chromedriver.exe'  # Update this to your path\n",
    "\n",
    "# Set up Chrome options to handle possible issues like proxy or network blocking\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--no-proxy-server')  # Disable proxy if needed\n",
    "chrome_options.add_argument('--remote-debugging-port=9222')  # Set custom debugging port\n",
    "\n",
    "# Initialize WebDriver Service\n",
    "service = Service(chrome_driver_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Target URL for NBA Teams page\n",
    "nba_url = \"https://www.nba.com/teams\"\n",
    "\n",
    "# CSV file name to store the team data\n",
    "csv_file_name = \"teams_NBA.csv\"\n",
    "\n",
    "try:\n",
    "    with open(csv_file_name, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "\n",
    "        # Write the header row for the CSV\n",
    "        csv_writer.writerow([\"Division\", \"Team Name\", \"Team Profile\", \"Team Stats\", \"Team Schedule\"])\n",
    "\n",
    "        driver.get(nba_url)\n",
    "\n",
    "        # Wait for the page to load completely\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"TeamDivisions_wrapper__5_SVo\"))\n",
    "        )\n",
    "\n",
    "        # Locate all team divisions\n",
    "        divisions = driver.find_elements(By.CLASS_NAME, \"TeamDivisions_division__u3KUS\")\n",
    "\n",
    "        for division in divisions:\n",
    "            division_name = division.find_element(By.CLASS_NAME, \"TeamDivisions_divisionName__KFlSk\").text\n",
    "            print(f\"Division: {division_name}\")\n",
    "\n",
    "            # Locate teams within the division\n",
    "            teams = division.find_elements(By.CLASS_NAME, \"TeamFigure_tf__jA5HW\")\n",
    "            for team in teams:\n",
    "                team_name = team.find_element(By.CLASS_NAME, \"TeamFigure_tfMainLink__OPLFu\").text\n",
    "                \n",
    "                # Get URLs for Profile, Stats, and Schedule\n",
    "                team_links = team.find_elements(By.CLASS_NAME, \"TeamFigureLink_teamFigureLink__uqnNO\")\n",
    "                team_profile = team_links[0].get_attribute(\"href\") if len(team_links) > 0 else \"N/A\"\n",
    "                team_stats = team_links[1].get_attribute(\"href\") if len(team_links) > 1 else \"N/A\"\n",
    "                team_schedule = team_links[2].get_attribute(\"href\") if len(team_links) > 2 else \"N/A\"\n",
    "\n",
    "                print(f\"  Team: {team_name}\")\n",
    "                print(f\"    Profile: {team_profile}\")\n",
    "                print(f\"    Stats: {team_stats}\")\n",
    "                print(f\"    Schedule: {team_schedule}\")\n",
    "\n",
    "                # Write the team data into the CSV\n",
    "                csv_writer.writerow([division_name, team_name, team_profile, team_stats, team_schedule])\n",
    "\n",
    "finally:\n",
    "    driver.quit()  # Ensure driver quits even if an error occurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teams's Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_name = \"teams_NBA.csv\"\n",
    "team_profile_list = []\n",
    "team_stats = []\n",
    "\n",
    "with open(csv_file_name, mode='r', encoding='utf-8') as csv_file:\n",
    "    reader = csv.DictReader(csv_file)\n",
    "    for row in reader:\n",
    "        team_profile_list.append(row[\"Team Profile\"])\n",
    "        team_stats.append(row[\"Team Stats\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process team profiles in batches (2 at a time)\n",
    "def process_batches(team_profile_list, batch_size=2, type=1):\n",
    "    all_rosters = []\n",
    "    # Process the URLs in batches of 2\n",
    "    for i in range(0, len(team_profile_list), batch_size):\n",
    "        batch = team_profile_list[i:i + batch_size]\n",
    "        batch_data = []\n",
    "\n",
    "        # Scrape data for each URL in the current batch\n",
    "        for url in batch:\n",
    "            try:\n",
    "                print(f\"Scraping data for {url}...\")\n",
    "                if type == 1:\n",
    "                    team_roster = scrape_roster(url)\n",
    "                    batch_data.extend(team_roster)\n",
    "                elif type == 2:\n",
    "                    team_retired = scrape_retired(url)\n",
    "                    batch_data.extend(team_retired)\n",
    "                elif type==3:\n",
    "                    team_hall_of_fame = scrape_hall_of_fame(url)\n",
    "                    batch_data.extend(team_hall_of_fame)\n",
    "                elif type==4:\n",
    "                    team_all_time_record = scrape_all_time_record(url)\n",
    "                    batch_data.extend(team_all_time_record)\n",
    "                elif type==5:\n",
    "                    team_achievements = scrape_achievements(url)\n",
    "                    batch_data.extend(team_achievements)\n",
    "                else:\n",
    "                    print(f\"Failed to retrieve roster for {url}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error scraping {url}: {e}\")\n",
    "\n",
    "            # Adding a random sleep between each request to prevent overwhelming the server\n",
    "            sleep(random.uniform(2, 5))\n",
    "\n",
    "        # Once the batch is done, add the data to the all_rosters list\n",
    "        all_rosters.extend(batch_data)\n",
    "\n",
    "        # Wait before processing the next batch to prevent rate-limiting issues\n",
    "        print(f\"Batch of {batch_size} teams processed. Waiting before next batch...\")\n",
    "        time.sleep(10)\n",
    "\n",
    "    return all_rosters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Function to scrape the team roster data\n",
    "def scrape_roster(url):\n",
    "    driver.get(url)\n",
    "    time.sleep(2)  # Wait for the page to load completely\n",
    "\n",
    "    # Wait for the team name section to load\n",
    "    try:\n",
    "        team_name_section = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"TeamHeader_name__MmHlP\"))\n",
    "        )\n",
    "    except:\n",
    "        print(f\"Unable to load the team name for {url}\")\n",
    "        return []\n",
    "\n",
    "    # Extract team name (both first and last name from div)\n",
    "    team_name_parts = team_name_section.find_elements(By.TAG_NAME, \"div\")\n",
    "    team_name = \" \".join([part.text.strip() for part in team_name_parts if part.text.strip()])\n",
    "\n",
    "    # Wait for the Roster section to load completely\n",
    "    try:\n",
    "        rows_section = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"TeamRoster_content__Owdiz\"))\n",
    "        )\n",
    "    except:\n",
    "        print(f\"Unable to load the roster section for {team_name}\")\n",
    "        return []\n",
    "\n",
    "    # Extract header for the CSV file\n",
    "    header = [\"Player\", \"#\", \"Pos\", \"Height\", \"Weight\", \"Birthdate\", \"Age\", \"Exp\", \"School\", \"How Acquired\", \"Team Name\", \"Player Link\"]\n",
    "\n",
    "    # Store the roster data\n",
    "    data = []\n",
    "\n",
    "    # Find all rows in the roster table\n",
    "    rows = rows_section.find_elements(By.XPATH, \".//tr\")\n",
    "\n",
    "    for row in rows[1:]:  # Skip header row\n",
    "        columns = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        if len(columns) > 0:\n",
    "            player_name = columns[0].text.strip()\n",
    "            player_link = columns[0].find_element(By.TAG_NAME, \"a\").get_attribute(\"href\") if columns[0].find_element(By.TAG_NAME, \"a\") else None\n",
    "            row_data = [col.text.strip() for col in columns]\n",
    "            row_data.append(team_name)  # Append team name\n",
    "            row_data.append(player_link)  # Append player link\n",
    "            data.append(row_data)\n",
    "\n",
    "    return data\n",
    "\n",
    "all_rosters = process_batches(team_profile_list, batch_size=2, type=1)\n",
    "\n",
    "# Write the data to CSV\n",
    "csv_file_name = \"nba_roster.csv\"\n",
    "header = [\"Player\", \"#\", \"Pos\", \"Height\", \"Weight\", \"Birthdate\", \"Age\", \"Exp\", \"School\", \"How Acquired\", \"Team Name\", \"Player Link\"]\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(header)  # Write header row\n",
    "    writer.writerows(all_rosters)  # Write roster rows\n",
    "\n",
    "print(f\"Roster data saved to {csv_file_name}\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RETIRED NUMBERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Function to scrape the team roster data\n",
    "def scrape_retired(url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load completely\n",
    "\n",
    "    # Wait for the team name section to load\n",
    "    try:\n",
    "        team_name_section = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"TeamHeader_name__MmHlP\"))\n",
    "        )\n",
    "        team_name_parts = team_name_section.find_elements(By.TAG_NAME, \"div\")\n",
    "        team_name = \" \".join([part.text.strip() for part in team_name_parts if part.text.strip()])\n",
    "    except:\n",
    "        print(f\"Unable to load the team name for {url}\")\n",
    "        return []\n",
    "\n",
    "    # Wait for the Roster section to load\n",
    "    try:\n",
    "        rows_section = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"TeamRetired_content__nb7Qt\"))\n",
    "        )\n",
    "        rows = rows_section.find_elements(By.XPATH, \".//tr\")\n",
    "    except:\n",
    "        print(f\"Unable to load the roster section for {team_name}\")\n",
    "        return []\n",
    "\n",
    "    # Extract header and data\n",
    "    data = []\n",
    "    for row in rows[1:]:  # Skip header row\n",
    "        columns = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        if len(columns) > 0:\n",
    "            player_link = None\n",
    "            try:\n",
    "                player_link = columns[1].find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "            except:\n",
    "                pass  # If no link exists, skip gracefully\n",
    "            \n",
    "            row_data = [\n",
    "                team_name,  # Team name\n",
    "                player_link,  # Player link\n",
    "                columns[1].text.strip(),  # Player name\n",
    "                columns[0].text.strip(),  # Jersey #\n",
    "                columns[2].text.strip(),  # Position\n",
    "                columns[3].text.strip(),  # Seasons with team\n",
    "                columns[4].text.strip(),  # Year of induction\n",
    "            ]\n",
    "            data.append(row_data)\n",
    "    return data\n",
    "\n",
    "all_retired = process_batches(team_profile_list, batch_size=2, type=2)\n",
    "\n",
    "# Write the data to CSV\n",
    "csv_file_name = \"nba_retired.csv\"\n",
    "header = [\"Team Name\", \"Player Link\", \"Player\", \"#\", \"Pos\", \"Seasons With Team\", \"Year of Induction\"]\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(header)  # Write header row\n",
    "    writer.writerows(all_retired)  # Write roster rows\n",
    "\n",
    "print(f\"Roster data saved to {csv_file_name}\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hall of Fame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Function to scrape Hall of Fame data\n",
    "def scrape_hall_of_fame(url):\n",
    "    driver.get(url)\n",
    "    time.sleep(2)  # Wait for the page to load completely\n",
    "\n",
    "    # Wait for the team name section to load\n",
    "    try:\n",
    "        team_name_section = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"TeamHeader_name__MmHlP\"))\n",
    "        )\n",
    "        team_name_parts = team_name_section.find_elements(By.TAG_NAME, \"div\")\n",
    "        team_name = \" \".join([part.text.strip() for part in team_name_parts if part.text.strip()])\n",
    "    except:\n",
    "        print(f\"Unable to load the team name for {url}\")\n",
    "        return []\n",
    "\n",
    "    # Wait for the Hall of Fame section to load\n",
    "    try:\n",
    "        hall_of_fame_section = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"TeamHallOfFame_content__IZSl2\"))\n",
    "        )\n",
    "        rows = hall_of_fame_section.find_elements(By.XPATH, \".//tr\")\n",
    "    except:\n",
    "        print(f\"Unable to load the Hall of Fame section for {team_name}\")\n",
    "        return []\n",
    "\n",
    "    # Extract Hall of Fame data\n",
    "    data = []\n",
    "    for row in rows[1:]:  # Skip header row\n",
    "        columns = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        if len(columns) > 0:\n",
    "            player_link = None\n",
    "            try:\n",
    "                player_link = columns[0].find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "            except:\n",
    "                pass  # If no link exists, skip gracefully\n",
    "            \n",
    "            row_data = [\n",
    "                team_name,  # Team name\n",
    "                player_link,  # Player link\n",
    "                columns[0].text.strip(),  # Player name\n",
    "                columns[1].text.strip(),  # Position\n",
    "                columns[2].text.strip(),  # Seasons with team\n",
    "                columns[3].text.strip(),  # Year of induction\n",
    "            ]\n",
    "            data.append(row_data)\n",
    "    return data\n",
    "\n",
    "all_hall_of_fame = process_batches(team_profile_list, batch_size=2, type=3)\n",
    "\n",
    "# Write the data to CSV\n",
    "csv_file_name = \"nba_hall_of_fame.csv\"\n",
    "header = [\"Team Name\", \"Player Link\", \"Player\", \"Pos\", \"Seasons With Team\", \"Year of Induction\"]\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(header)  # Write header row\n",
    "    writer.writerows(all_hall_of_fame)  # Write Hall of Fame rows\n",
    "\n",
    "print(f\"Hall of Fame data saved to {csv_file_name}\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All-time records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Function to scrape All-Time Record data\n",
    "def scrape_all_time_record(url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load completely\n",
    "\n",
    "    # Wait for the team name section to load\n",
    "    try:\n",
    "        team_name_section = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"TeamHeader_name__MmHlP\"))\n",
    "        )\n",
    "        team_name_parts = team_name_section.find_elements(By.TAG_NAME, \"div\")\n",
    "        team_name = \" \".join([part.text.strip() for part in team_name_parts if part.text.strip()])\n",
    "    except:\n",
    "        print(f\"Unable to load the team name for {url}\")\n",
    "        return []\n",
    "\n",
    "    # Wait for the All-Time Record section to load\n",
    "    try:\n",
    "        records_section = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"TeamRecords_table__0iapO\"))\n",
    "        )\n",
    "        rows = records_section.find_elements(By.XPATH, \".//tr\")\n",
    "    except:\n",
    "        print(f\"Unable to load the All-Time Record section for {team_name}\")\n",
    "        return []\n",
    "\n",
    "    # Extract All-Time Record data\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        columns = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        if len(columns) > 0:\n",
    "            player_link = None\n",
    "            try:\n",
    "                player_link = columns[1].find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "            except:\n",
    "                pass  # If no link exists, skip gracefully\n",
    "            \n",
    "            row_data = [\n",
    "                team_name,  # Team name\n",
    "                columns[0].text.strip(),  # Record type (e.g., \"Total Points\")\n",
    "                columns[1].text.strip(),  # Player name\n",
    "                player_link,  # Player link\n",
    "                columns[2].text.strip(),  # Stat value\n",
    "            ]\n",
    "            data.append(row_data)\n",
    "    return data\n",
    "\n",
    "\n",
    "all_time_records = process_batches(team_profile_list, batch_size=2, type=4)\n",
    "\n",
    "# Write the data to CSV\n",
    "csv_file_name = \"nba_all_time_records.csv\"\n",
    "header = [\"Team Name\", \"Record Type\", \"Player\", \"Player Link\", \"Stat Value\"]\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(header)  # Write header row\n",
    "    writer.writerows(all_time_records)  # Write All-Time Record rows\n",
    "\n",
    "print(f\"All-Time Record data saved to {csv_file_name}\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Achievement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for https://www.nba.com/team/1610612738/celtics/...\n",
      "Scraping data for https://www.nba.com/team/1610612751/nets/...\n",
      "Batch of 2 teams processed. Waiting before next batch...\n",
      "Scraping data for https://www.nba.com/team/1610612752/knicks/...\n",
      "Scraping data for https://www.nba.com/team/1610612755/sixers/...\n",
      "Batch of 2 teams processed. Waiting before next batch...\n",
      "Scraping data for https://www.nba.com/team/1610612761/raptors/...\n",
      "Scraping data for https://www.nba.com/team/1610612741/bulls/...\n",
      "Batch of 2 teams processed. Waiting before next batch...\n",
      "Scraping data for https://www.nba.com/team/1610612739/cavaliers/...\n",
      "Scraping data for https://www.nba.com/team/1610612765/pistons/...\n",
      "Batch of 2 teams processed. Waiting before next batch...\n",
      "Scraping data for https://www.nba.com/team/1610612754/pacers/...\n",
      "Scraping data for https://www.nba.com/team/1610612749/bucks/...\n",
      "Batch of 2 teams processed. Waiting before next batch...\n",
      "Scraping data for https://www.nba.com/team/1610612737/hawks/...\n",
      "Scraping data for https://www.nba.com/team/1610612766/hornets/...\n",
      "Batch of 2 teams processed. Waiting before next batch...\n",
      "Scraping data for https://www.nba.com/team/1610612748/heat/...\n",
      "Scraping data for https://www.nba.com/team/1610612753/magic/...\n",
      "Batch of 2 teams processed. Waiting before next batch...\n",
      "Scraping data for https://www.nba.com/team/1610612764/wizards/...\n",
      "Scraping data for https://www.nba.com/team/1610612743/nuggets/...\n",
      "Batch of 2 teams processed. Waiting before next batch...\n",
      "Scraping data for https://www.nba.com/team/1610612750/timberwolves/...\n",
      "Scraping data for https://www.nba.com/team/1610612760/thunder/...\n",
      "Batch of 2 teams processed. Waiting before next batch...\n",
      "Scraping data for https://www.nba.com/team/1610612757/blazers/...\n",
      "Scraping data for https://www.nba.com/team/1610612762/jazz/...\n",
      "Batch of 2 teams processed. Waiting before next batch...\n",
      "Scraping data for https://www.nba.com/team/1610612744/warriors/...\n",
      "Scraping data for https://www.nba.com/team/1610612746/clippers/...\n",
      "Batch of 2 teams processed. Waiting before next batch...\n",
      "Scraping data for https://www.nba.com/team/1610612747/lakers/...\n",
      "Scraping data for https://www.nba.com/team/1610612756/suns/...\n",
      "Batch of 2 teams processed. Waiting before next batch...\n",
      "Scraping data for https://www.nba.com/team/1610612758/kings/...\n",
      "Scraping data for https://www.nba.com/team/1610612742/mavericks/...\n",
      "Batch of 2 teams processed. Waiting before next batch...\n",
      "Scraping data for https://www.nba.com/team/1610612745/rockets/...\n",
      "Error scraping https://www.nba.com/team/1610612745/rockets/: name 'TimeoutException' is not defined\n",
      "Scraping data for https://www.nba.com/team/1610612763/grizzlies/...\n",
      "Batch of 2 teams processed. Waiting before next batch...\n",
      "Scraping data for https://www.nba.com/team/1610612740/pelicans/...\n",
      "Scraping data for https://www.nba.com/team/1610612759/spurs/...\n",
      "Batch of 2 teams processed. Waiting before next batch...\n",
      "Achievement data saved to nba_achievements.csv\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "def scrape_achievements(url):\n",
    "    driver.get(url)\n",
    "    time.sleep(2)  # Wait for the page to load completely\n",
    "\n",
    "    # Wait for the Achievements section to load\n",
    "    try:\n",
    "        awards_sections = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CLASS_NAME, \"TeamAwards_group__XU0o9\"))\n",
    "        )\n",
    "    except TimeoutException:\n",
    "        print(f\"Unable to load the Achievements section for {url}\")\n",
    "        return []\n",
    "    \n",
    "    # Wait for the team name section to load\n",
    "    try:\n",
    "        team_name_section = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"TeamHeader_name__MmHlP\"))\n",
    "        )\n",
    "        team_name_parts = team_name_section.find_elements(By.TAG_NAME, \"div\")\n",
    "        team_name = \" \".join([part.text.strip() for part in team_name_parts if part.text.strip()])\n",
    "    except:\n",
    "        print(f\"Unable to load the team name for {url}\")\n",
    "        return []\n",
    "\n",
    "    # Extracting Achievements: Championship Wins, Conference Titles, Division Titles\n",
    "    data = []\n",
    "\n",
    "    try:\n",
    "        # Extract each category of awards\n",
    "        for group in awards_sections:\n",
    "            # Extracting the heading (e.g., \"Championship Wins\", \"Conference Titles\", \"Division Titles\")\n",
    "            try:\n",
    "                heading = group.find_element(By.CLASS_NAME, \"TeamAwards_heading__BvLNE\").text.strip()\n",
    "            except NoSuchElementException:\n",
    "                print(\"Heading not found in group.\")\n",
    "                continue\n",
    "            \n",
    "            # Extracting the list of years under each heading\n",
    "            try:\n",
    "                years_list = group.find_elements(By.CLASS_NAME, \"TeamAwards_listItem__rb4hz\")\n",
    "                for year in years_list:\n",
    "                    row_data = [team_name, heading, year.text.strip()]\n",
    "                    data.append(row_data)\n",
    "            except NoSuchElementException:\n",
    "                print(f\"No years found for {heading}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error while processing awards: {e}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "# Process the team profiles\n",
    "all_achievements = process_batches(team_profile_list, batch_size=2, type=5)\n",
    "\n",
    "# Write the data to CSV\n",
    "csv_file_name = \"nba_achievements.csv\"\n",
    "header = [\"Team Name\", \"Achievement Type\", \"Year\"]\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(header)  # Write header row\n",
    "    writer.writerows(all_achievements)  # Write achievement rows\n",
    "\n",
    "print(f\"Achievement data saved to {csv_file_name}\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team's Stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.nba.com/stats/team/1610612738/traditional',\n",
       " 'https://www.nba.com/stats/team/1610612751/traditional',\n",
       " 'https://www.nba.com/stats/team/1610612752/traditional',\n",
       " 'https://www.nba.com/stats/team/1610612755/traditional',\n",
       " 'https://www.nba.com/stats/team/1610612761/traditional',\n",
       " 'https://www.nba.com/stats/team/1610612741/traditional',\n",
       " 'https://www.nba.com/stats/team/1610612739/traditional',\n",
       " 'https://www.nba.com/stats/team/1610612765/traditional',\n",
       " 'https://www.nba.com/stats/team/1610612754/traditional',\n",
       " 'https://www.nba.com/stats/team/1610612749/traditional',\n",
       " 'https://www.nba.com/stats/team/1610612737/traditional',\n",
       " 'https://www.nba.com/stats/team/1610612766/traditional',\n",
       " 'https://www.nba.com/stats/team/1610612748/traditional',\n",
       " 'https://www.nba.com/stats/team/1610612753/traditional',\n",
       " 'https://www.nba.com/stats/team/1610612764/traditional',\n",
       " 'https://www.nba.com/stats/team/1610612743/traditional',\n",
       " 'https://www.nba.com/stats/team/1610612750/traditional',\n",
       " 'https://www.nba.com/stats/team/1610612760/traditional',\n",
       " 'https://www.nba.com/stats/team/1610612757/traditional',\n",
       " 'https://www.nba.com/stats/team/1610612762/traditional',\n",
       " 'https://www.nba.com/stats/team/1610612744/traditional',\n",
       " 'https://www.nba.com/stats/team/1610612746/traditional',\n",
       " 'https://www.nba.com/stats/team/1610612747/traditional',\n",
       " 'https://www.nba.com/stats/team/1610612756/traditional',\n",
       " 'https://www.nba.com/stats/team/1610612758/traditional',\n",
       " 'https://www.nba.com/stats/team/1610612742/traditional',\n",
       " 'https://www.nba.com/stats/team/1610612745/traditional',\n",
       " 'https://www.nba.com/stats/team/1610612763/traditional',\n",
       " 'https://www.nba.com/stats/team/1610612740/traditional',\n",
       " 'https://www.nba.com/stats/team/1610612759/traditional']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_stats = [team_stat + '/traditional' for team_stat in team_stats]\n",
    "\n",
    "team_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for URL: https://www.nba.com/stats/team/1610612738/traditional\n",
      "Team Name: BOSTON CELTICS\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Scraping data for year: 2001-02\n",
      "Scraping data for year: 2000-01\n",
      "Scraping data for year: 1999-00\n",
      "Scraping data for year: 1998-99\n",
      "Scraping data for year: 1997-98\n",
      "Scraping data for year: 1996-97\n",
      "Scraping data for URL: https://www.nba.com/stats/team/1610612751/traditional\n",
      "Team Name: BROOKLYN NETS\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Scraping data for year: 2001-02\n",
      "Scraping data for year: 2000-01\n",
      "Scraping data for year: 1999-00\n",
      "Scraping data for year: 1998-99\n",
      "Scraping data for year: 1997-98\n",
      "Scraping data for year: 1996-97\n",
      "Scraping data for URL: https://www.nba.com/stats/team/1610612752/traditional\n",
      "Team Name: NEW YORK KNICKS\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Scraping data for year: 2001-02\n",
      "Scraping data for year: 2000-01\n",
      "Scraping data for year: 1999-00\n",
      "Scraping data for year: 1998-99\n",
      "Scraping data for year: 1997-98\n",
      "Scraping data for year: 1996-97\n",
      "Scraping data for URL: https://www.nba.com/stats/team/1610612755/traditional\n",
      "Team Name: PHILADELPHIA 76ERS\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Scraping data for year: 2001-02\n",
      "Scraping data for year: 2000-01\n",
      "Scraping data for year: 1999-00\n",
      "Scraping data for year: 1998-99\n",
      "Scraping data for year: 1997-98\n",
      "Scraping data for year: 1996-97\n",
      "Scraping data for URL: https://www.nba.com/stats/team/1610612761/traditional\n",
      "Team Name: TORONTO RAPTORS\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Scraping data for year: 2001-02\n",
      "Scraping data for year: 2000-01\n",
      "Scraping data for year: 1999-00\n",
      "Scraping data for year: 1998-99\n",
      "Scraping data for year: 1997-98\n",
      "Scraping data for year: 1996-97\n",
      "Scraping data for URL: https://www.nba.com/stats/team/1610612741/traditional\n",
      "Team Name: CHICAGO BULLS\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Scraping data for year: 2001-02\n",
      "Scraping data for year: 2000-01\n",
      "Scraping data for year: 1999-00\n",
      "Scraping data for year: 1998-99\n",
      "Scraping data for year: 1997-98\n",
      "Scraping data for year: 1996-97\n",
      "Scraping data for URL: https://www.nba.com/stats/team/1610612739/traditional\n",
      "Team Name: CLEVELAND CAVALIERS\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Scraping data for year: 2001-02\n",
      "Scraping data for year: 2000-01\n",
      "Scraping data for year: 1999-00\n",
      "Scraping data for year: 1998-99\n",
      "Scraping data for year: 1997-98\n",
      "Scraping data for year: 1996-97\n",
      "Scraping data for URL: https://www.nba.com/stats/team/1610612765/traditional\n",
      "Team Name: DETROIT PISTONS\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Scraping data for year: 2001-02\n",
      "Scraping data for year: 2000-01\n",
      "Scraping data for year: 1999-00\n",
      "Scraping data for year: 1998-99\n",
      "Scraping data for year: 1997-98\n",
      "Scraping data for year: 1996-97\n",
      "Scraping data for URL: https://www.nba.com/stats/team/1610612754/traditional\n",
      "Team Name: INDIANA PACERS\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Scraping data for year: 2001-02\n",
      "Scraping data for year: 2000-01\n",
      "Scraping data for year: 1999-00\n",
      "Scraping data for year: 1998-99\n",
      "Scraping data for year: 1997-98\n",
      "Scraping data for year: 1996-97\n",
      "Scraping data for URL: https://www.nba.com/stats/team/1610612749/traditional\n",
      "Team Name: MILWAUKEE BUCKS\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Scraping data for year: 2001-02\n",
      "Scraping data for year: 2000-01\n",
      "Scraping data for year: 1999-00\n",
      "Scraping data for year: 1998-99\n",
      "Scraping data for year: 1997-98\n",
      "Scraping data for year: 1996-97\n",
      "Scraping data for URL: https://www.nba.com/stats/team/1610612737/traditional\n",
      "Team Name: ATLANTA HAWKS\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Scraping data for year: 2001-02\n",
      "Scraping data for year: 2000-01\n",
      "Scraping data for year: 1999-00\n",
      "Scraping data for year: 1998-99\n",
      "Scraping data for year: 1997-98\n",
      "Scraping data for year: 1996-97\n",
      "Scraping data for URL: https://www.nba.com/stats/team/1610612766/traditional\n",
      "Team Name: CHARLOTTE HORNETS\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Error scraping data for year 2002-03: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6425E3A95+28005]\n",
      "\t(No symbol) [0x00007FF642548390]\n",
      "\t(No symbol) [0x00007FF6423E580A]\n",
      "\t(No symbol) [0x00007FF642435A3E]\n",
      "\t(No symbol) [0x00007FF642435D2C]\n",
      "\t(No symbol) [0x00007FF64247EA97]\n",
      "\t(No symbol) [0x00007FF64245BA7F]\n",
      "\t(No symbol) [0x00007FF64247B8B3]\n",
      "\t(No symbol) [0x00007FF64245B7E3]\n",
      "\t(No symbol) [0x00007FF6424275C8]\n",
      "\t(No symbol) [0x00007FF642428731]\n",
      "\tGetHandleVerifier [0x00007FF6428D641D+3118829]\n",
      "\tGetHandleVerifier [0x00007FF642926C70+3448640]\n",
      "\tGetHandleVerifier [0x00007FF64291CEED+3408317]\n",
      "\tGetHandleVerifier [0x00007FF6426AA3EB+841403]\n",
      "\t(No symbol) [0x00007FF6425533EF]\n",
      "\t(No symbol) [0x00007FF64254F464]\n",
      "\t(No symbol) [0x00007FF64254F5FD]\n",
      "\t(No symbol) [0x00007FF64253EB59]\n",
      "\tBaseThreadInitThunk [0x00007FFACF66259D+29]\n",
      "\tRtlUserThreadStart [0x00007FFAD040AF38+40]\n",
      "\n",
      "Scraping data for year: 2001-02\n",
      "Scraping data for year: 2000-01\n",
      "Scraping data for year: 1999-00\n",
      "Scraping data for year: 1998-99\n",
      "Scraping data for year: 1997-98\n",
      "Scraping data for year: 1996-97\n",
      "Scraping data for URL: https://www.nba.com/stats/team/1610612748/traditional\n",
      "Team Name: MIAMI HEAT\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Scraping data for year: 2001-02\n",
      "Scraping data for year: 2000-01\n",
      "Scraping data for year: 1999-00\n",
      "Scraping data for year: 1998-99\n",
      "Scraping data for year: 1997-98\n",
      "Scraping data for year: 1996-97\n",
      "Scraping data for URL: https://www.nba.com/stats/team/1610612753/traditional\n",
      "Team Name: ORLANDO MAGIC\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Scraping data for year: 2001-02\n",
      "Scraping data for year: 2000-01\n",
      "Scraping data for year: 1999-00\n",
      "Scraping data for year: 1998-99\n",
      "Scraping data for year: 1997-98\n",
      "Scraping data for year: 1996-97\n",
      "Scraping data for URL: https://www.nba.com/stats/team/1610612764/traditional\n",
      "Team Name: WASHINGTON WIZARDS\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Scraping data for year: 2001-02\n",
      "Scraping data for year: 2000-01\n",
      "Scraping data for year: 1999-00\n",
      "Scraping data for year: 1998-99\n",
      "Scraping data for year: 1997-98\n",
      "Scraping data for year: 1996-97\n",
      "Scraping data for URL: https://www.nba.com/stats/team/1610612743/traditional\n",
      "Team Name: DENVER NUGGETS\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Scraping data for year: 2001-02\n",
      "Scraping data for year: 2000-01\n",
      "Scraping data for year: 1999-00\n",
      "Scraping data for year: 1998-99\n",
      "Scraping data for year: 1997-98\n",
      "Scraping data for year: 1996-97\n",
      "Scraping data for URL: https://www.nba.com/stats/team/1610612750/traditional\n",
      "Team Name: MINNESOTA TIMBERWOLVES\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Error scraping data for year 2006-07: Message: stale element reference: stale element not found in the current frame\n",
      "  (Session info: chrome=130.0.6723.117); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6425E3A95+28005]\n",
      "\t(No symbol) [0x00007FF642548390]\n",
      "\t(No symbol) [0x00007FF6423E580A]\n",
      "\t(No symbol) [0x00007FF6423EC2CC]\n",
      "\t(No symbol) [0x00007FF6423EE5E7]\n",
      "\t(No symbol) [0x00007FF6423EE6A0]\n",
      "\t(No symbol) [0x00007FF64242F9DB]\n",
      "\t(No symbol) [0x00007FF64245BA3A]\n",
      "\t(No symbol) [0x00007FF642429246]\n",
      "\t(No symbol) [0x00007FF64245BC50]\n",
      "\t(No symbol) [0x00007FF64247B8B3]\n",
      "\t(No symbol) [0x00007FF64245B7E3]\n",
      "\t(No symbol) [0x00007FF6424275C8]\n",
      "\t(No symbol) [0x00007FF642428731]\n",
      "\tGetHandleVerifier [0x00007FF6428D641D+3118829]\n",
      "\tGetHandleVerifier [0x00007FF642926C70+3448640]\n",
      "\tGetHandleVerifier [0x00007FF64291CEED+3408317]\n",
      "\tGetHandleVerifier [0x00007FF6426AA3EB+841403]\n",
      "\t(No symbol) [0x00007FF6425533EF]\n",
      "\t(No symbol) [0x00007FF64254F464]\n",
      "\t(No symbol) [0x00007FF64254F5FD]\n",
      "\t(No symbol) [0x00007FF64253EB59]\n",
      "\tBaseThreadInitThunk [0x00007FFACF66259D+29]\n",
      "\tRtlUserThreadStart [0x00007FFAD040AF38+40]\n",
      "\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Scraping data for year: 2001-02\n",
      "Scraping data for year: 2000-01\n",
      "Scraping data for year: 1999-00\n",
      "Scraping data for year: 1998-99\n",
      "Scraping data for year: 1997-98\n",
      "Scraping data for year: 1996-97\n",
      "Scraping data for URL: https://www.nba.com/stats/team/1610612760/traditional\n",
      "Team Name: OKLAHOMA CITY THUNDER\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Scraping data for year: 2001-02\n",
      "Scraping data for year: 2000-01\n",
      "Scraping data for year: 1999-00\n",
      "Scraping data for year: 1998-99\n",
      "Scraping data for year: 1997-98\n",
      "Scraping data for year: 1996-97\n",
      "Scraping data for URL: https://www.nba.com/stats/team/1610612757/traditional\n",
      "Team Name: PORTLAND TRAIL BLAZERS\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Scraping data for year: 2001-02\n",
      "Scraping data for year: 2000-01\n",
      "Scraping data for year: 1999-00\n",
      "Scraping data for year: 1998-99\n",
      "Scraping data for year: 1997-98\n",
      "Scraping data for year: 1996-97\n",
      "Scraping data for URL: https://www.nba.com/stats/team/1610612762/traditional\n",
      "Team Name: UTAH JAZZ\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Scraping data for year: 2001-02\n",
      "Scraping data for year: 2000-01\n",
      "Scraping data for year: 1999-00\n",
      "Scraping data for year: 1998-99\n",
      "Scraping data for year: 1997-98\n",
      "Scraping data for year: 1996-97\n",
      "Scraping data for URL: https://www.nba.com/stats/team/1610612744/traditional\n",
      "Team Name: GOLDEN STATE WARRIORS\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Scraping data for year: 2001-02\n",
      "Scraping data for year: 2000-01\n",
      "Scraping data for year: 1999-00\n",
      "Scraping data for year: 1998-99\n",
      "Scraping data for year: 1997-98\n",
      "Scraping data for year: 1996-97\n",
      "Scraping data for URL: https://www.nba.com/stats/team/1610612746/traditional\n",
      "Team Name: LA CLIPPERS\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Scraping data for year: 2001-02\n",
      "Scraping data for year: 2000-01\n",
      "Scraping data for year: 1999-00\n",
      "Scraping data for year: 1998-99\n",
      "Scraping data for year: 1997-98\n",
      "Scraping data for year: 1996-97\n",
      "Scraping data for URL: https://www.nba.com/stats/team/1610612747/traditional\n",
      "Team Name: LOS ANGELES LAKERS\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Scraping data for year: 2001-02\n",
      "Scraping data for year: 2000-01\n",
      "Scraping data for year: 1999-00\n",
      "Scraping data for year: 1998-99\n",
      "Scraping data for year: 1997-98\n",
      "Scraping data for year: 1996-97\n",
      "Scraping data for URL: https://www.nba.com/stats/team/1610612756/traditional\n",
      "Team Name: PHOENIX SUNS\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Scraping data for year: 2001-02\n",
      "Scraping data for year: 2000-01\n",
      "Scraping data for year: 1999-00\n",
      "Scraping data for year: 1998-99\n",
      "Scraping data for year: 1997-98\n",
      "Scraping data for year: 1996-97\n",
      "Scraping data for URL: https://www.nba.com/stats/team/1610612758/traditional\n",
      "Team Name: SACRAMENTO KINGS\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Scraping data for year: 2001-02\n",
      "Scraping data for year: 2000-01\n",
      "Scraping data for year: 1999-00\n",
      "Scraping data for year: 1998-99\n",
      "Scraping data for year: 1997-98\n",
      "Scraping data for year: 1996-97\n",
      "Scraping data for URL: https://www.nba.com/stats/team/1610612742/traditional\n",
      "Team Name: DALLAS MAVERICKS\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Scraping data for year: 2001-02\n",
      "Scraping data for year: 2000-01\n",
      "Scraping data for year: 1999-00\n",
      "Scraping data for year: 1998-99\n",
      "Scraping data for year: 1997-98\n",
      "Scraping data for year: 1996-97\n",
      "Scraping data for URL: https://www.nba.com/stats/team/1610612745/traditional\n",
      "Team Name: HOUSTON ROCKETS\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Scraping data for year: 2001-02\n",
      "Scraping data for year: 2000-01\n",
      "Scraping data for year: 1999-00\n",
      "Scraping data for year: 1998-99\n",
      "Scraping data for year: 1997-98\n",
      "Scraping data for year: 1996-97\n",
      "Scraping data for URL: https://www.nba.com/stats/team/1610612763/traditional\n",
      "Team Name: MEMPHIS GRIZZLIES\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Scraping data for year: 2001-02\n",
      "Scraping data for year: 2000-01\n",
      "Scraping data for year: 1999-00\n",
      "Scraping data for year: 1998-99\n",
      "Scraping data for year: 1997-98\n",
      "Scraping data for year: 1996-97\n",
      "Scraping data for URL: https://www.nba.com/stats/team/1610612740/traditional\n",
      "Team Name: NEW ORLEANS PELICANS\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Scraping data for URL: https://www.nba.com/stats/team/1610612759/traditional\n",
      "Team Name: SAN ANTONIO SPURS\n",
      "Scraping data for year: 2024-25\n",
      "Scraping data for year: 2023-24\n",
      "Scraping data for year: 2022-23\n",
      "Scraping data for year: 2021-22\n",
      "Scraping data for year: 2020-21\n",
      "Scraping data for year: 2019-20\n",
      "Scraping data for year: 2018-19\n",
      "Scraping data for year: 2017-18\n",
      "Scraping data for year: 2016-17\n",
      "Scraping data for year: 2015-16\n",
      "Scraping data for year: 2014-15\n",
      "Scraping data for year: 2013-14\n",
      "Scraping data for year: 2012-13\n",
      "Scraping data for year: 2011-12\n",
      "Scraping data for year: 2010-11\n",
      "Scraping data for year: 2009-10\n",
      "Scraping data for year: 2008-09\n",
      "Scraping data for year: 2007-08\n",
      "Scraping data for year: 2006-07\n",
      "Scraping data for year: 2005-06\n",
      "Scraping data for year: 2004-05\n",
      "Scraping data for year: 2003-04\n",
      "Scraping data for year: 2002-03\n",
      "Scraping data for year: 2001-02\n",
      "Scraping data for year: 2000-01\n",
      "Scraping data for year: 1999-00\n",
      "Scraping data for year: 1998-99\n",
      "Scraping data for year: 1997-98\n",
      "Scraping data for year: 1996-97\n",
      "Data saved to nba_team_stats.csv\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Function to scrape the table data for a given year\n",
    "def scrape_table_data():\n",
    "    table_data = []\n",
    "    # Wait for the table to load\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"Crom_table__p1iZz\"))\n",
    "    )\n",
    "    \n",
    "    # Locate the table\n",
    "    table = driver.find_element(By.CLASS_NAME, \"Crom_table__p1iZz\")\n",
    "    \n",
    "    # Extract headers and their titles\n",
    "    headers = table.find_element(By.TAG_NAME, \"thead\").find_elements(By.TAG_NAME, \"th\")\n",
    "    header_data = []\n",
    "    for header in headers:\n",
    "        field = header.get_attribute(\"field\")  # e.g., \"GP\"\n",
    "        title = header.get_attribute(\"title\")  # e.g., \"Game Played\"\n",
    "        header_data.append((field, title))\n",
    "    \n",
    "    # Extract rows\n",
    "    body = table.find_element(By.TAG_NAME, \"tbody\")\n",
    "    rows = body.find_elements(By.TAG_NAME, \"tr\")\n",
    "    for row in rows:\n",
    "        cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        row_data = [col.text.strip() for col in cols]\n",
    "        table_data.append(row_data)\n",
    "    \n",
    "    return header_data, table_data\n",
    "\n",
    "# Function to get the team name\n",
    "def get_team_name():\n",
    "    try:\n",
    "        team_name_section = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"TeamHeader_name__MmHlP\"))\n",
    "        )\n",
    "        team_name_parts = team_name_section.find_elements(By.TAG_NAME, \"div\")\n",
    "        team_name = \" \".join([part.text.strip() for part in team_name_parts if part.text.strip()])\n",
    "        return team_name\n",
    "    except:\n",
    "        print(\"Unable to load the team name\")\n",
    "        return \"Unknown Team\"\n",
    "\n",
    "# Main function to scrape all years\n",
    "def scrape_all_years(url):\n",
    "    driver.get(url)\n",
    "    time.sleep(2)  # Wait for the page to load\n",
    "    \n",
    "    # Get the team name\n",
    "    team_name = get_team_name()\n",
    "    print(f\"Team Name: {team_name}\")\n",
    "    \n",
    "    # Wait for the dropdown to appear\n",
    "    dropdown = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"DropDown_select__4pIg9\"))\n",
    "    )\n",
    "    \n",
    "    # Get all options from the dropdown\n",
    "    select = Select(dropdown)\n",
    "    all_years = [option.get_attribute(\"value\") for option in select.options if option.get_attribute(\"value\")]\n",
    "\n",
    "    all_data = []\n",
    "    \n",
    "    # Iterate over each year, select it, and scrape the table data\n",
    "    for year in all_years:\n",
    "        print(f\"Scraping data for year: {year}\")\n",
    "        select.select_by_value(year)\n",
    "        time.sleep(2)  # Allow the page to refresh with the new data\n",
    "        \n",
    "        try:\n",
    "            header_data, table_data = scrape_table_data()\n",
    "            # Append the year and team name to the data\n",
    "            for row in table_data:\n",
    "                row.insert(0, year)  # Add year to the start of each row\n",
    "                row.insert(0, team_name)  # Add team name to the start of each row\n",
    "            all_data.extend(table_data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping data for year {year}: {e}\")\n",
    "    \n",
    "    return header_data, all_data\n",
    "\n",
    "# Initialize CSV file only once\n",
    "csv_file_name = \"nba_team_stats.csv\"\n",
    "with open(csv_file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write headers later after determining them\n",
    "    header_written = False\n",
    "    \n",
    "    # Loop through each URL in the list\n",
    "    for url in team_stats:  # `team_stats` should be a list of URLs\n",
    "        print(f\"Scraping data for URL: {url}\")\n",
    "        \n",
    "        try:\n",
    "            # Scrape data for the current URL\n",
    "            header_data, all_data = scrape_all_years(url)\n",
    "            \n",
    "            if not header_written:\n",
    "                # Write the headers only once\n",
    "                writer.writerow([\"Team Name\", \"Year\"] + [f\"{field} - {title}\" for field, title in header_data])\n",
    "                header_written = True\n",
    "            \n",
    "            # Write the data rows\n",
    "            writer.writerows(all_data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping data for {url}: {e}\")\n",
    "\n",
    "print(f\"Data saved to {csv_file_name}\")\n",
    "\n",
    "# Close the driver after all URLs are processed\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
