{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **[Data4Life] - Introduction to Data Science**\n",
    "Topic ***NBA*** - Group ***16***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Team Members**\n",
    "\n",
    "<center>\n",
    "\n",
    "| No. | Name                   | Student ID |\n",
    "|-----|------------------------|------------|\n",
    "| 1   | Trần Nguyễn Nhật Cường | 22127048   |\n",
    "| 2   | Huỳnh Tấn Đạt          | 22127059   |\n",
    "| 3   | Nguyễn Công Tuấn       | 22127436   |  \n",
    "| 4   | Trần Đăng Tuấn         | 22127438   |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Content**\n",
    "1. [Overview](#overview)\n",
    "2. [Libraries](#libraries)\n",
    "3. [Data Collection](#collect)\n",
    "    - [Official NBA Stat](#web1)\n",
    "    - [Basketball Reference](#web1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Overview** <div id = \"overview\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will identify two specific URLs which are:\n",
    "- [Offcial NBA Stat](https://www.nba.com/stats)\n",
    "- [Basketball Reference](https://www.basketball-reference.com/)\n",
    "\n",
    "Our team will use for data crawling to support our analysis. The targeted data types include:\n",
    "- Team Statistics (Total): Comprehensive data summarizing team performance metrics.\n",
    "- Player Statistics (Total): Aggregate performance data for individual players across relevant metrics.\n",
    "- Player Information: Detailed player profiles, including demographic, biographical, and career-specific information.\n",
    "- Rookie Player Statistics: Performance metrics specific to rookie players in the league.\n",
    "\n",
    "These URLs will serve as primary data sources, enabling us to compile and analyze the necessary information effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Libraries**<div id = \"libraries\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import selenium\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "# from selenium.webdriver.support.ui import Select\n",
    "# import pandas as pd\n",
    "# import time\n",
    "# import csv\n",
    "# import json\n",
    "# import time\n",
    "# import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Data Collection** <div id = \"collect\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.1 Offcial NBA Stat** <div id = \"web1\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Player's profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "# # Function to scrape the team roster data\n",
    "# def scrape_roster(url, season):\n",
    "#     driver.get(url)\n",
    "\n",
    "#     time.sleep(2)  # Wait for the page to load completely\n",
    "\n",
    "#     # Wait for the team name section to load\n",
    "#     try:\n",
    "#         team_name_section = WebDriverWait(driver, 10).until(\n",
    "#             EC.presence_of_element_located((By.CLASS_NAME, \"TeamHeader_name__MmHlP\"))\n",
    "#         )\n",
    "#     except:\n",
    "#         print(f\"Unable to load the team name for {url}\")\n",
    "#         return []\n",
    "\n",
    "#     # Extract team name\n",
    "#     team_name_parts = team_name_section.find_elements(By.TAG_NAME, \"div\")\n",
    "#     team_name = \" \".join(\n",
    "#         [part.text.strip() for part in team_name_parts if part.text.strip()]\n",
    "#     )\n",
    "\n",
    "#     # Wait for the Roster section to load completely\n",
    "#     try:\n",
    "#         rows_section = WebDriverWait(driver, 10).until(\n",
    "#             EC.presence_of_element_located((By.CLASS_NAME, \"Crom_body__UYOcU\"))\n",
    "#         )\n",
    "#     except:\n",
    "#         print(f\"Unable to load the roster section for {team_name}\")\n",
    "#         return []\n",
    "\n",
    "#     # Extract header for the CSV file\n",
    "#     header = [\n",
    "#         \"Player\",\n",
    "#         \"No.\",\n",
    "#         \"Pos\",\n",
    "#         \"Height\",\n",
    "#         \"Weight\",\n",
    "#         \"Birthdate\",\n",
    "#         \"Age\",\n",
    "#         \"Exp\",\n",
    "#         \"School\",\n",
    "#         \"How Acquired\",\n",
    "#         \"Team Name\",\n",
    "#         \"Player Link\",\n",
    "#         \"Season\",\n",
    "#     ]\n",
    "\n",
    "#     # Store the roster data\n",
    "#     data = []\n",
    "\n",
    "#     # Find all rows in the roster table\n",
    "#     rows = rows_section.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "#     for row in rows:\n",
    "#         columns = row.find_elements(By.TAG_NAME, \"td\")\n",
    "\n",
    "#         # Ensure row has data columns\n",
    "#         if len(columns) > 0:\n",
    "#             player_name = columns[0].text.strip()\n",
    "#             player_link_elements = columns[0].find_elements(By.TAG_NAME, \"a\")\n",
    "#             player_link = (\n",
    "#                 player_link_elements[0].get_attribute(\"href\")\n",
    "#                 if player_link_elements\n",
    "#                 else None\n",
    "#             )\n",
    "\n",
    "#             # Extract other data columns\n",
    "#             row_data = [col.text.strip() for col in columns]\n",
    "#             row_data.append(team_name)  # Append team name\n",
    "#             row_data.append(player_link)  # Append player link\n",
    "#             row_data.append(season)  # Append season\n",
    "\n",
    "#             data.append(row_data)\n",
    "\n",
    "#     return data\n",
    "\n",
    "\n",
    "# # Usage of the function\n",
    "# all_rosters = process_batches(team_stats, batch_size=2, type=1)\n",
    "\n",
    "# # Write the data to CSV\n",
    "# csv_file_name = \"nba_roster_1.csv\"\n",
    "\n",
    "# header = [\n",
    "#     \"Player\",\n",
    "#     \"#\",\n",
    "#     \"Pos\",\n",
    "#     \"Height\",\n",
    "#     \"Weight\",\n",
    "#     \"Birthdate\",\n",
    "#     \"Age\",\n",
    "#     \"Exp\",\n",
    "#     \"School\",\n",
    "#     \"How Acquired\",\n",
    "#     \"Team Name\",\n",
    "#     \"Player Link\",\n",
    "#     \"Season\",\n",
    "# ]\n",
    "\n",
    "\n",
    "# with open(csv_file_name, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "#     writer = csv.writer(csv_file)\n",
    "#     writer.writerow(header)  # Write header row\n",
    "#     writer.writerows(all_rosters)  # Write roster rows\n",
    "\n",
    "# print(f\"Roster data saved to {csv_file_name}\")\n",
    "\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Player stat total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = webdriver.Chrome()\n",
    "# url = \"https://www.nba.com/stats/leaders\"\n",
    "# url_season = [\n",
    "#     \"?Season=2024-25\",\n",
    "#     \"?Season=2023-24\",\n",
    "#     \"?Season=2022-23\",\n",
    "#     \"?Season=2021-22\",\n",
    "#     \"?Season=2020-21\",\n",
    "# ]\n",
    "\n",
    "# data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in url_season:\n",
    "#     driver.get(url + i)\n",
    "#     time.sleep(2)  # Allow the page to load\n",
    "\n",
    "#     # Wait for the pagination element to appear\n",
    "#     try:\n",
    "#         pagination = WebDriverWait(driver, 10).until(\n",
    "#             EC.presence_of_element_located(\n",
    "#                 (By.XPATH, '//div[contains(@class, \"Pagination_content\")]')\n",
    "#             )\n",
    "#         )\n",
    "#         page = int(pagination.find_element(By.XPATH, \".//div[4]\").text.split(\" \")[-1])\n",
    "#     except Exception as e:\n",
    "#         print(f\"Pagination element not found: {e}\")\n",
    "#         continue\n",
    "\n",
    "#     # Locate table headers\n",
    "#     headers = driver.find_element(By.XPATH, '//tr[contains(@class, \"Crom_headers\")]')\n",
    "#     columns = [header.text for header in headers.find_elements(By.TAG_NAME, \"th\")]\n",
    "#     columns.append(\"Season\")  # Add a season column\n",
    "\n",
    "#     # Temporary DataFrame for the current season\n",
    "#     season_data = pd.DataFrame(columns=columns)\n",
    "\n",
    "#     for _ in range(page):\n",
    "#         # Locate table rows\n",
    "#         table = WebDriverWait(driver, 10).until(\n",
    "#             EC.presence_of_element_located(\n",
    "#                 (By.XPATH, '//tbody[contains(@class, \"Crom_body\")]')\n",
    "#             )\n",
    "#         )\n",
    "#         rows = table.find_elements(By.XPATH, \".//tr\")\n",
    "\n",
    "#         for row in rows:\n",
    "#             cells = row.find_elements(By.XPATH, \".//td\")\n",
    "#             row_data = [cell.text for cell in cells]\n",
    "#             if row_data:  # Avoid empty rows\n",
    "#                 row_data.append(i.split(\"=\")[-1])  # Add the season\n",
    "#                 season_data.loc[len(season_data)] = row_data\n",
    "\n",
    "#         # Click the next page button\n",
    "#         try:\n",
    "#             button = WebDriverWait(driver, 10).until(\n",
    "#                 EC.element_to_be_clickable(\n",
    "#                     (\n",
    "#                         By.XPATH,\n",
    "#                         './/button[@type=\"button\" and @title=\"Next Page Button\"]',\n",
    "#                     )\n",
    "#                 )\n",
    "#             )\n",
    "#             driver.execute_script(\n",
    "#                 \"arguments[0].click();\", button\n",
    "#             )  # Ensure no overlay blocks the click\n",
    "#             time.sleep(3)  # Wait for the next page to load\n",
    "#         except Exception as e:\n",
    "#             print(f\"Pagination error: {e}\")\n",
    "#             break\n",
    "\n",
    "#     # Append the season's data to the main DataFrame\n",
    "#     data = pd.concat([data, season_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save to CSV\n",
    "# path = \"../../Data_NBA_1/nba_stats.csv\"\n",
    "# data.to_csv(path, index=False, header=True)\n",
    "# print(f\"Data saved to {path}\")\n",
    "\n",
    "# # Close the browser\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Team's Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Target URL for NBA Teams page\n",
    "# nba_url = \"https://www.nba.com/teams\"\n",
    "\n",
    "# # CSV file name to store the team data\n",
    "# csv_file_name = \"teams_NBA.csv\"\n",
    "\n",
    "# try:\n",
    "#     with open(csv_file_name, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "#         csv_writer = csv.writer(csv_file)\n",
    "\n",
    "#         # Write the header row for the CSV\n",
    "#         csv_writer.writerow(\n",
    "#             [\"Division\", \"Team Name\", \"Team Profile\", \"Team Stats\", \"Team Schedule\"]\n",
    "#         )\n",
    "\n",
    "#         driver.get(nba_url)\n",
    "\n",
    "#         # Wait for the page to load completely\n",
    "#         WebDriverWait(driver, 10).until(\n",
    "#             EC.presence_of_element_located(\n",
    "#                 (By.CLASS_NAME, \"TeamDivisions_wrapper__5_SVo\")\n",
    "#             )\n",
    "#         )\n",
    "\n",
    "#         # Locate all team divisions\n",
    "#         divisions = driver.find_elements(By.CLASS_NAME, \"TeamDivisions_division__u3KUS\")\n",
    "\n",
    "#         for division in divisions:\n",
    "#             division_name = division.find_element(\n",
    "#                 By.CLASS_NAME, \"TeamDivisions_divisionName__KFlSk\"\n",
    "#             ).text\n",
    "#             print(f\"Division: {division_name}\")\n",
    "\n",
    "#             # Locate teams within the division\n",
    "#             teams = division.find_elements(By.CLASS_NAME, \"TeamFigure_tf__jA5HW\")\n",
    "#             for team in teams:\n",
    "#                 team_name = team.find_element(\n",
    "#                     By.CLASS_NAME, \"TeamFigure_tfMainLink__OPLFu\"\n",
    "#                 ).text\n",
    "\n",
    "#                 # Get URLs for Profile, Stats, and Schedule\n",
    "#                 team_links = team.find_elements(\n",
    "#                     By.CLASS_NAME, \"TeamFigureLink_teamFigureLink__uqnNO\"\n",
    "#                 )\n",
    "#                 team_profile = (\n",
    "#                     team_links[0].get_attribute(\"href\")\n",
    "#                     if len(team_links) > 0\n",
    "#                     else \"N/A\"\n",
    "#                 )\n",
    "#                 team_stats = (\n",
    "#                     team_links[1].get_attribute(\"href\")\n",
    "#                     if len(team_links) > 1\n",
    "#                     else \"N/A\"\n",
    "#                 )\n",
    "#                 team_schedule = (\n",
    "#                     team_links[2].get_attribute(\"href\")\n",
    "#                     if len(team_links) > 2\n",
    "#                     else \"N/A\"\n",
    "#                 )\n",
    "\n",
    "#                 print(f\"  Team: {team_name}\")\n",
    "#                 print(f\"    Profile: {team_profile}\")\n",
    "#                 print(f\"    Stats: {team_stats}\")\n",
    "#                 print(f\"    Schedule: {team_schedule}\")\n",
    "\n",
    "#                 # Write the team data into the CSV\n",
    "#                 csv_writer.writerow(\n",
    "#                     [division_name, team_name, team_profile, team_stats, team_schedule]\n",
    "#                 )\n",
    "\n",
    "# finally:\n",
    "#     driver.quit()  # Ensure driver quits even if an error occurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Team's stat total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_file_name = \"teams_NBA.csv\"\n",
    "# team_profile_list = []\n",
    "# team_stats = []\n",
    "\n",
    "# url_season = [\n",
    "#     \"?Season=2024-25\",\n",
    "#     \"?Season=2023-24\",\n",
    "#     \"?Season=2022-23\",\n",
    "#     \"?Season=2021-22\",\n",
    "#     \"?Season=2020-21\",\n",
    "# ]\n",
    "\n",
    "# with open(csv_file_name, mode=\"r\", encoding=\"utf-8\") as csv_file:\n",
    "#     reader = csv.DictReader(csv_file)\n",
    "#     for row in reader:\n",
    "#         team_profile_list.append(row[\"Team Profile\"])\n",
    "#         for season_query in url_season:\n",
    "#             team_stats.append(row[\"Team Stats\"] + season_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# # Function to scrape the table data for a given year\n",
    "# def scrape_table_data():\n",
    "#     table_data = []\n",
    "\n",
    "#     # Wait for the table to load\n",
    "#     WebDriverWait(driver, 10).until(\n",
    "#         EC.presence_of_element_located((By.CLASS_NAME, \"Crom_table__p1iZz\"))\n",
    "#     )\n",
    "\n",
    "#     # Locate the table\n",
    "#     table = driver.find_element(By.CLASS_NAME, \"Crom_table__p1iZz\")\n",
    "\n",
    "#     # Extract headers and their titles\n",
    "#     headers = table.find_element(By.TAG_NAME, \"thead\").find_elements(By.TAG_NAME, \"th\")\n",
    "#     header_data = []\n",
    "\n",
    "#     for header in headers:\n",
    "#         field = header.get_attribute(\"field\")  # e.g., \"GP\"\n",
    "#         title = header.get_attribute(\"title\")  # e.g., \"Game Played\"\n",
    "#         header_data.append((field, title))\n",
    "\n",
    "#     # Extract rows\n",
    "#     body = table.find_element(By.TAG_NAME, \"tbody\")\n",
    "#     rows = body.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "#     for row in rows:\n",
    "#         cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "#         row_data = [col.text.strip() for col in cols]\n",
    "#         table_data.append(row_data)\n",
    "#     return header_data, table_data\n",
    "\n",
    "\n",
    "# # Function to get the team name\n",
    "# def get_team_name():\n",
    "#     try:\n",
    "#         team_name_section = WebDriverWait(driver, 10).until(\n",
    "#             EC.presence_of_element_located((By.CLASS_NAME, \"TeamHeader_name__MmHlP\"))\n",
    "#         )\n",
    "\n",
    "#         team_name_parts = team_name_section.find_elements(By.TAG_NAME, \"div\")\n",
    "\n",
    "#         team_name = \" \".join(\n",
    "#             [part.text.strip() for part in team_name_parts if part.text.strip()]\n",
    "#         )\n",
    "#         return team_name\n",
    "#     except:\n",
    "#         print(\"Unable to load the team name\")\n",
    "#         return \"Unknown Team\"\n",
    "\n",
    "\n",
    "# # Main function to scrape all years\n",
    "# def scrape_all_years(url):\n",
    "#     driver.get(url)\n",
    "#     time.sleep(2)  # Wait for the page to load\n",
    "\n",
    "#     # Get the team name\n",
    "#     team_name = get_team_name()\n",
    "\n",
    "#     # Wait for the dropdown to appear\n",
    "#     dropdown = WebDriverWait(driver, 10).until(\n",
    "#         EC.presence_of_element_located((By.CLASS_NAME, \"DropDown_select__4pIg9\"))\n",
    "#     )\n",
    "\n",
    "#     # Get all options from the dropdown\n",
    "#     select = Select(dropdown)\n",
    "#     all_years = [\n",
    "#         option.get_attribute(\"value\")\n",
    "#         for option in select.options\n",
    "#         if option.get_attribute(\"value\")\n",
    "#     ]\n",
    "#     all_data = []\n",
    "\n",
    "#     # Iterate over each year, select it, and scrape the table data\n",
    "#     for year in all_years:\n",
    "#         print(f\"Scraping data for year: {year}\")\n",
    "#         select.select_by_value(year)\n",
    "#         time.sleep(2)  # Allow the page to refresh with the new data\n",
    "#         try:\n",
    "#             header_data, table_data = scrape_table_data()\n",
    "#             # Append the year and team name to the data\n",
    "#             for row in table_data:\n",
    "#                 row.insert(0, year)  # Add year to the start of each row\n",
    "#                 row.insert(0, team_name)  # Add team name to the start of each row\n",
    "#             all_data.extend(table_data)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error scraping data for year {year}: {e}\")\n",
    "#     return header_data, all_data\n",
    "\n",
    "\n",
    "# # Initialize CSV file only once\n",
    "# csv_file_name = \"nba_team_stats.csv\"\n",
    "\n",
    "# with open(csv_file_name, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write headers later after determining them\n",
    "#     header_written = False\n",
    "\n",
    "#     # Loop through each URL in the list\n",
    "#     for url in team_stats:  # `team_stats` should be a list of URLs\n",
    "#         try:\n",
    "#             # Scrape data for the current URL\n",
    "#             header_data, all_data = scrape_all_years(url)\n",
    "\n",
    "#             if not header_written:\n",
    "#                 # Write the headers only once\n",
    "#                 writer.writerow(\n",
    "#                     [\"Team Name\", \"Year\"]\n",
    "#                     + [f\"{field} - {title}\" for field, title in header_data]\n",
    "#                 )\n",
    "#                 header_written = True\n",
    "#             # Write the data rows\n",
    "#             writer.writerows(all_data)\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error scraping data for {url}: {e}\")\n",
    "\n",
    "\n",
    "# print(f\"Data saved to {csv_file_name}\")\n",
    "# # Close the driver after all URLs are processed\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2 Basketball Reference** <div id = \"web2\"></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Player's profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Player's stat total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Team's Profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Team's stat total"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
